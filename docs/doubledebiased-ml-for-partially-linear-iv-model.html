<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 20 Double/Debiased ML for Partially Linear IV Model | Machine Learning and Causal Inference</title>
  <meta name="description" content="Chapter 20 Double/Debiased ML for Partially Linear IV Model | Machine Learning and Causal Inference" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 20 Double/Debiased ML for Partially Linear IV Model | Machine Learning and Causal Inference" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 20 Double/Debiased ML for Partially Linear IV Model | Machine Learning and Causal Inference" />
  
  
  

<meta name="author" content="Alexander Quispe &amp; Anzony Quispe" />


<meta name="date" content="2021-11-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"/>
<link rel="next" href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning and Causal Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="predictive-inference.html"><a href="predictive-inference.html"><i class="fa fa-check"></i><b>2</b> Predictive Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="predictive-inference.html"><a href="predictive-inference.html#data"><i class="fa fa-check"></i><b>2.1</b> Data</a></li>
<li class="chapter" data-level="2.2" data-path="predictive-inference.html"><a href="predictive-inference.html#data-analysis"><i class="fa fa-check"></i><b>2.2</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="predictive-inference.html"><a href="predictive-inference.html#r-and-python-code"><i class="fa fa-check"></i><b>2.2.1</b> R and Python code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="predictive-inference.html"><a href="predictive-inference.html#prediction-question"><i class="fa fa-check"></i><b>2.3</b> Prediction Question</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="predictive-inference.html"><a href="predictive-inference.html#basic-model"><i class="fa fa-check"></i><b>2.3.1</b> Basic Model:</a></li>
<li class="chapter" data-level="2.3.2" data-path="predictive-inference.html"><a href="predictive-inference.html#flexible-model"><i class="fa fa-check"></i><b>2.3.2</b> Flexible Model:</a></li>
<li class="chapter" data-level="2.3.3" data-path="predictive-inference.html"><a href="predictive-inference.html#lasso-model"><i class="fa fa-check"></i><b>2.3.3</b> Lasso Model:</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="predictive-inference.html"><a href="predictive-inference.html#data-splitting"><i class="fa fa-check"></i><b>2.4</b> Data Splitting</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html"><i class="fa fa-check"></i><b>3</b> Predictive Inference The Gender Wage Gap</a>
<ul>
<li class="chapter" data-level="3.1" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#data-analysis-1"><i class="fa fa-check"></i><b>3.1</b> Data analysis</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#ols-regression"><i class="fa fa-check"></i><b>3.1.1</b> OLS Regression</a></li>
<li class="chapter" data-level="3.1.2" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#ols-regression-with-controls"><i class="fa fa-check"></i><b>3.1.2</b> Ols regression with controls</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#partialling-out-using-ols"><i class="fa fa-check"></i><b>3.2</b> Partialling-Out using ols</a></li>
<li class="chapter" data-level="3.3" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#partialling-out-using-lasso"><i class="fa fa-check"></i><b>3.3</b> Partialling-Out using lasso</a></li>
<li class="chapter" data-level="3.4" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#extra-flexible-model"><i class="fa fa-check"></i><b>3.4</b> “Extra” flexible model</a></li>
<li class="chapter" data-level="3.5" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#laso-extra-flexible-model"><i class="fa fa-check"></i><b>3.5</b> Laso “Extra” Flexible model</a></li>
<li class="chapter" data-level="3.6" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#summarize-the-results"><i class="fa fa-check"></i><b>3.6</b> Summarize the results</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html"><i class="fa fa-check"></i><b>4</b> Simple Exercise on Overfitting</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html#first-set-pn"><i class="fa fa-check"></i><b>4.1</b> 1. First set p=n</a></li>
<li class="chapter" data-level="4.2" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html#second-set-pn2."><i class="fa fa-check"></i><b>4.2</b> 2. Second, set p=n/2.</a></li>
<li class="chapter" data-level="4.3" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html#third-set-pn-.05"><i class="fa fa-check"></i><b>4.3</b> 3. Third, set p/n =.05</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vaccine-rct-examples.html"><a href="vaccine-rct-examples.html"><i class="fa fa-check"></i><b>5</b> Vaccine RCT Examples</a>
<ul>
<li class="chapter" data-level="5.1" data-path="vaccine-rct-examples.html"><a href="vaccine-rct-examples.html#polio-rct"><i class="fa fa-check"></i><b>5.1</b> Polio RCT</a></li>
<li class="chapter" data-level="5.2" data-path="vaccine-rct-examples.html"><a href="vaccine-rct-examples.html#pfizerbntx-covid-19-rct"><i class="fa fa-check"></i><b>5.2</b> Pfizer/BNTX Covid-19 RCT</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="penalized-linear-regressions-a-simulation-experiment.html"><a href="penalized-linear-regressions-a-simulation-experiment.html"><i class="fa fa-check"></i><b>6</b> Penalized Linear Regressions: A Simulation Experiment</a>
<ul>
<li class="chapter" data-level="6.1" data-path="penalized-linear-regressions-a-simulation-experiment.html"><a href="penalized-linear-regressions-a-simulation-experiment.html#data-generating-process-approximately-sparse"><i class="fa fa-check"></i><b>6.1</b> Data Generating Process: Approximately Sparse</a></li>
<li class="chapter" data-level="6.2" data-path="penalized-linear-regressions-a-simulation-experiment.html"><a href="penalized-linear-regressions-a-simulation-experiment.html#data-generating-process-approximately-sparse-small-dense-part"><i class="fa fa-check"></i><b>6.2</b> Data Generating Process: Approximately Sparse + Small Dense Part</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="simulation-design.html"><a href="simulation-design.html"><i class="fa fa-check"></i><b>7</b> Simulation Design</a>
<ul>
<li class="chapter" data-level="7.1" data-path="simulation-design.html"><a href="simulation-design.html#example-1"><i class="fa fa-check"></i><b>7.1</b> Example 1</a></li>
<li class="chapter" data-level="7.2" data-path="simulation-design.html"><a href="simulation-design.html#example-2"><i class="fa fa-check"></i><b>7.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html"><i class="fa fa-check"></i><b>8</b> Testing the Convergence Hypothesis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#data-analysis-2"><i class="fa fa-check"></i><b>8.2</b> Data analysis</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#ols"><i class="fa fa-check"></i><b>8.2.1</b> OLS</a></li>
<li class="chapter" data-level="8.2.2" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#lasso"><i class="fa fa-check"></i><b>8.2.2</b> Lasso</a></li>
<li class="chapter" data-level="8.2.3" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#summary-results"><i class="fa fa-check"></i><b>8.2.3</b> Summary results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html"><i class="fa fa-check"></i><b>9</b> Machine Learning for wage prediction</a>
<ul>
<li class="chapter" data-level="9.1" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#data-1"><i class="fa fa-check"></i><b>9.1</b> Data</a></li>
<li class="chapter" data-level="9.2" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#analysis"><i class="fa fa-check"></i><b>9.2</b> Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#ols-1"><i class="fa fa-check"></i><b>9.3</b> OLS</a></li>
<li class="chapter" data-level="9.4" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#lasso-ridge-and-elastic-net"><i class="fa fa-check"></i><b>9.4</b> Lasso, Ridge and Elastic Net</a></li>
<li class="chapter" data-level="9.5" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#non-linear-models"><i class="fa fa-check"></i><b>9.5</b> Non-linear models</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#regression-trees"><i class="fa fa-check"></i><b>9.5.1</b> Regression Trees</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#random-forest-and-boosted-trees"><i class="fa fa-check"></i><b>9.6</b> Random Forest and Boosted Trees</a></li>
<li class="chapter" data-level="9.7" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#results"><i class="fa fa-check"></i><b>9.7</b> Results</a></li>
<li class="chapter" data-level="9.8" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#ensemble-learning"><i class="fa fa-check"></i><b>9.8</b> Ensemble learning</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="deep-neural-networks-for-wage-prediction.html"><a href="deep-neural-networks-for-wage-prediction.html"><i class="fa fa-check"></i><b>10</b> Deep Neural Networks for Wage Prediction</a>
<ul>
<li class="chapter" data-level="10.1" data-path="deep-neural-networks-for-wage-prediction.html"><a href="deep-neural-networks-for-wage-prediction.html#data-preparation"><i class="fa fa-check"></i><b>10.1</b> Data Preparation</a></li>
<li class="chapter" data-level="10.2" data-path="deep-neural-networks-for-wage-prediction.html"><a href="deep-neural-networks-for-wage-prediction.html#neural-networks"><i class="fa fa-check"></i><b>10.2</b> Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html"><i class="fa fa-check"></i><b>11</b> Functional Approximations by Trees and Neural Networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#functional-approximation-by-a-tree"><i class="fa fa-check"></i><b>11.1</b> Functional Approximation by a Tree</a></li>
<li class="chapter" data-level="11.2" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#functional-approximation-by-rf"><i class="fa fa-check"></i><b>11.2</b> Functional Approximation by RF</a></li>
<li class="chapter" data-level="11.3" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#boosted-trees"><i class="fa fa-check"></i><b>11.3</b> Boosted Trees</a></li>
<li class="chapter" data-level="11.4" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#same-example-with-a-neural-network"><i class="fa fa-check"></i><b>11.4</b> Same Example with a Neural Network</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><i class="fa fa-check"></i><b>12</b> Causal Identification in DAGs using Backdoor and Swigs, Equivalence Classes, Falsifiability Tests</a>
<ul>
<li class="chapter" data-level="12.1" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#graph-generation-and-plotting"><i class="fa fa-check"></i><b>12.1</b> Graph Generation and Plotting</a></li>
<li class="chapter" data-level="12.2" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#report-relatives-of-x2"><i class="fa fa-check"></i><b>12.2</b> Report Relatives of X2</a></li>
<li class="chapter" data-level="12.3" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#find-paths-between-d-and-y"><i class="fa fa-check"></i><b>12.3</b> Find Paths Between D and Y</a></li>
<li class="chapter" data-level="12.4" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#list-all-testable-implications-of-the-model"><i class="fa fa-check"></i><b>12.4</b> List All Testable Implications of the Model</a></li>
<li class="chapter" data-level="12.5" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#identification-by-backdoor-list-minimal-adjustment-sets-to-identify-causal-effecs-d-to-y"><i class="fa fa-check"></i><b>12.5</b> Identification by Backdoor: List minimal adjustment sets to identify causal effecs <span class="math inline">\(D \to Y\)</span></a></li>
<li class="chapter" data-level="12.6" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#identification-via-swig-and-d-separation"><i class="fa fa-check"></i><b>12.6</b> Identification via SWIG and D-separation</a></li>
<li class="chapter" data-level="12.7" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#deduce-conditional-exogeneity-or-ignorability-by-d-separation"><i class="fa fa-check"></i><b>12.7</b> Deduce Conditional Exogeneity or Ignorability by D-separation</a></li>
<li class="chapter" data-level="12.8" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#print-all-average-effects-identifiable-by-conditioning"><i class="fa fa-check"></i><b>12.8</b> Print All Average Effects Identifiable by Conditioning</a></li>
<li class="chapter" data-level="12.9" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#equivalence-classes"><i class="fa fa-check"></i><b>12.9</b> Equivalence Classes</a></li>
<li class="chapter" data-level="12.10" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#example-of-testing-dag-validity"><i class="fa fa-check"></i><b>12.10</b> Example of Testing DAG Validity</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="dosearch-for-causal-identification-in-dags.html"><a href="dosearch-for-causal-identification-in-dags.html"><i class="fa fa-check"></i><b>13</b> Dosearch for Causal Identification in DAGs</a></li>
<li class="chapter" data-level="14" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><i class="fa fa-check"></i><b>14</b> A Case Study: The Effect of Gun Ownership on Gun-Homicide Rates</a>
<ul>
<li class="chapter" data-level="14.1" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#data-2"><i class="fa fa-check"></i><b>14.1</b> Data</a></li>
<li class="chapter" data-level="14.2" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#preprocessing."><i class="fa fa-check"></i><b>14.2</b> Preprocessing.</a></li>
<li class="chapter" data-level="14.3" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#the-effect-of-gun-ownership"><i class="fa fa-check"></i><b>14.3</b> The effect of gun ownership</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#ols-2"><i class="fa fa-check"></i><b>14.3.1</b> OLS</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#dml-algorithm"><i class="fa fa-check"></i><b>14.4</b> DML algorithm</a></li>
<li class="chapter" data-level="14.5" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#lasso-1"><i class="fa fa-check"></i><b>14.5</b> Lasso</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#random-forest"><i class="fa fa-check"></i><b>14.5.1</b> Random Forest</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><a href="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><i class="fa fa-check"></i><b>15</b> The Effect of Gun Ownership on Gun-Homicide Rates using DML for neural nets</a>
<ul>
<li class="chapter" data-level="15.1" data-path="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><a href="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html#dml-for-neural-nets"><i class="fa fa-check"></i><b>15.1</b> DML for neural nets</a></li>
<li class="chapter" data-level="15.2" data-path="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><a href="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html#estimating-the-effect-with-dlm-for-neural-nets"><i class="fa fa-check"></i><b>15.2</b> Estimating the effect with DLM for neural nets</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><i class="fa fa-check"></i><b>16</b> Inference on Predictive and Causal Effects in High-Dimensional Nonlinear Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#impact-of-401k-on-financial-wealth"><i class="fa fa-check"></i><b>16.1</b> Impact of 401(k) on Financial Wealth</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#data-3"><i class="fa fa-check"></i><b>16.1.1</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#double-ml-package"><i class="fa fa-check"></i><b>16.2</b> Double ML package</a></li>
<li class="chapter" data-level="16.3" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#estimating-the-ate-of-401k-eligibility-on-net-financial-assets"><i class="fa fa-check"></i><b>16.3</b> Estimating the ATE of 401(k) Eligibility on Net Financial Assets</a></li>
<li class="chapter" data-level="16.4" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#partially-linear-regression-models-plr"><i class="fa fa-check"></i><b>16.4</b> Partially Linear Regression Models (PLR)</a></li>
<li class="chapter" data-level="16.5" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#interactive-regression-model-irm"><i class="fa fa-check"></i><b>16.5</b> Interactive Regression Model (IRM)</a></li>
<li class="chapter" data-level="16.6" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#local-average-treatment-effects-of-401k-participation-on-net-financial-assets"><i class="fa fa-check"></i><b>16.6</b> Local Average Treatment Effects of 401(k) Participation on Net Financial Assets</a></li>
<li class="chapter" data-level="16.7" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#interactive-iv-model-iivm"><i class="fa fa-check"></i><b>16.7</b> Interactive IV Model (IIVM)</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><i class="fa fa-check"></i><b>17</b> Using Dagitty in the Analysis of Impact of 401(k) on Net Financial Wealth</a>
<ul>
<li class="chapter" data-level="17.1" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#graphs-for-401k-analsyis"><i class="fa fa-check"></i><b>17.1</b> Graphs for 401(K) Analsyis</a></li>
<li class="chapter" data-level="17.2" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#state-one-graph-where-f-determines-x-and-plot-it"><i class="fa fa-check"></i><b>17.2</b> State one graph (where F determines X) and plot it</a></li>
<li class="chapter" data-level="17.3" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#list-minimal-adjustment-sets-to-identify-causal-effecs-d-to-y"><i class="fa fa-check"></i><b>17.3</b> List minimal adjustment sets to identify causal effecs <span class="math inline">\(D \to Y\)</span></a></li>
<li class="chapter" data-level="17.4" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#what-is-the-underlying-principle"><i class="fa fa-check"></i><b>17.4</b> What is the underlying principle?</a></li>
<li class="chapter" data-level="17.5" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#another-graph-wherere-x-determine-f"><i class="fa fa-check"></i><b>17.5</b> Another Graph (wherere <span class="math inline">\(X\)</span> determine <span class="math inline">\(F\)</span>):</a></li>
<li class="chapter" data-level="17.6" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#one-more-graph-encompassing-previous-ones-where-f-x-are-jointly-determined-by-latent-factors-a.-we-can-allow-in-fact-the-whole-triple-d-f-x-to-be-jointly-determined-by-latent-factors-a."><i class="fa fa-check"></i><b>17.6</b> One more graph (encompassing previous ones), where (F, X) are jointly determined by latent factors <span class="math inline">\(A\)</span>. We can allow in fact the whole triple (D, F, X) to be jointly determined by latent factors <span class="math inline">\(A\)</span>.</a></li>
<li class="chapter" data-level="17.7" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#threat-to-idenitification-what-if-f-also-directly-affects-y-note-that-there-are-no-valid-adjustment-sets-in-this-case"><i class="fa fa-check"></i><b>17.7</b> Threat to Idenitification: What if <span class="math inline">\(F\)</span> also directly affects <span class="math inline">\(Y\)</span>? (Note that there are no valid adjustment sets in this case)</a></li>
<li class="chapter" data-level="17.8" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#introduce-match-amount-m-very-important-mediator-why-mediator.-m-is-not-observed.-luckily-adjusting-for-x-still-works-if-there-is-no-f-to-m-arrow."><i class="fa fa-check"></i><b>17.8</b> Introduce Match Amount <span class="math inline">\(M\)</span> (very important mediator, why mediator?). <span class="math inline">\(M\)</span> is not observed. Luckily adjusting for <span class="math inline">\(X\)</span> still works if there is no <span class="math inline">\(F \to M\)</span> arrow.</a></li>
<li class="chapter" data-level="17.9" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#if-there-is-f-to-m-arrow-then-adjusting-for-x-is-not-sufficient."><i class="fa fa-check"></i><b>17.9</b> If there is <span class="math inline">\(F \to M\)</span> arrow, then adjusting for <span class="math inline">\(X\)</span> is not sufficient.</a></li>
<li class="chapter" data-level="17.10" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#question"><i class="fa fa-check"></i><b>17.10</b> Question:</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html"><a href="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html"><i class="fa fa-check"></i><b>18</b> Double/Debiased Machine Learning for the Partially Linear Regression Model.</a>
<ul>
<li class="chapter" data-level="18.1" data-path="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html"><a href="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html#dml-algorithm-1"><i class="fa fa-check"></i><b>18.1</b> DML algorithm</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><i class="fa fa-check"></i><b>19</b> Sensititivy Analysis for Unobserved Confounder with DML and Sensmakr</a>
<ul>
<li class="chapter" data-level="19.1" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#here-we-experiment-with-using-package-sensemakr-in-conjunction-with-debiased-ml"><i class="fa fa-check"></i><b>19.1</b> Here we experiment with using package “sensemakr” in conjunction with debiased ML</a></li>
<li class="chapter" data-level="19.2" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#we-will-work-on"><i class="fa fa-check"></i><b>19.2</b> We will work on:</a></li>
<li class="chapter" data-level="19.3" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#take-out-village-fixed-effects-and-run-basic-linear-analysis"><i class="fa fa-check"></i><b>19.3</b> Take out village fixed effects and run basic linear analysis</a></li>
<li class="chapter" data-level="19.4" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#we-first-use-lasso-for-partilling-out-controls"><i class="fa fa-check"></i><b>19.4</b> We first use Lasso for Partilling Out Controls</a></li>
<li class="chapter" data-level="19.5" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#manual-bias-analysis"><i class="fa fa-check"></i><b>19.5</b> Manual Bias Analysis</a></li>
<li class="chapter" data-level="19.6" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#bias-analysis-with-sensemakr"><i class="fa fa-check"></i><b>19.6</b> Bias Analysis with Sensemakr</a></li>
<li class="chapter" data-level="19.7" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#next-we-use-random-forest-as-ml-tool-for-partialling-out"><i class="fa fa-check"></i><b>19.7</b> Next We use Random Forest as ML tool for Partialling Out</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html"><i class="fa fa-check"></i><b>20</b> Double/Debiased ML for Partially Linear IV Model</a>
<ul>
<li class="chapter" data-level="20.1" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#partially-linear-iv-model"><i class="fa fa-check"></i><b>20.1</b> Partially Linear IV Model</a></li>
<li class="chapter" data-level="20.2" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#example"><i class="fa fa-check"></i><b>20.2</b> Example</a></li>
<li class="chapter" data-level="20.3" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#plivm-in-residualized-form"><i class="fa fa-check"></i><b>20.3</b> PLIVM in Residualized Form</a></li>
<li class="chapter" data-level="20.4" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#dml-for-pliv-model"><i class="fa fa-check"></i><b>20.4</b> DML for PLIV Model</a></li>
<li class="chapter" data-level="20.5" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#emprical-example-acemoglu-jonsohn-robinson-aer."><i class="fa fa-check"></i><b>20.5</b> Emprical Example: Acemoglu, Jonsohn, Robinson (AER).</a></li>
<li class="chapter" data-level="20.6" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#examine-if-we-have-weak-instruments"><i class="fa fa-check"></i><b>20.6</b> Examine if we have weak instruments</a></li>
<li class="chapter" data-level="20.7" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#we-do-have-weak-instruments-because-t-stats-in-regression-tilde-d-sim-tilde-z-are-less-than-4-in-absolute-value"><i class="fa fa-check"></i><b>20.7</b> We do have weak instruments, because t-stats in regression <span class="math inline">\(\tilde D \sim \tilde Z\)</span> are less than 4 in absolute value</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><i class="fa fa-check"></i><b>21</b> A Simple Example of Properties of IV estimator when Instruments are Weak</a>
<ul>
<li class="chapter" data-level="21.1" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#run-1000-trials-to-evaluate-distribution-of-the-iv-estimator"><i class="fa fa-check"></i><b>21.1</b> Run 1000 trials to evaluate distribution of the IV estimator</a></li>
<li class="chapter" data-level="21.2" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#plot-the-actual-distribution-against-the-normal-approximation-based-on-strong-instrument-assumption"><i class="fa fa-check"></i><b>21.2</b> Plot the Actual Distribution against the Normal Approximation (based on Strong Instrument Assumption)</a></li>
<li class="chapter" data-level="21.3" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#some-help-functions"><i class="fa fa-check"></i><b>21.3</b> Some Help Functions</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html"><i class="fa fa-check"></i><b>22</b> HTE I: Binary treatment</a>
<ul>
<li class="chapter" data-level="22.1" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#pre-specified-hypotheses"><i class="fa fa-check"></i><b>22.1</b> Pre-specified hypotheses</a></li>
<li class="chapter" data-level="22.2" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#data-driven-hypotheses"><i class="fa fa-check"></i><b>22.2</b> Data-driven hypotheses</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#via-causal-trees"><i class="fa fa-check"></i><b>22.2.1</b> Via causal trees</a></li>
<li class="chapter" data-level="22.2.2" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#via-grf"><i class="fa fa-check"></i><b>22.2.2</b> Via grf</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#further-reading"><i class="fa fa-check"></i><b>22.3</b> Further reading</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="doubledebiased-ml-for-partially-linear-iv-model" class="section level1" number="20">
<h1><span class="header-section-number">Chapter 20</span> Double/Debiased ML for Partially Linear IV Model</h1>
<p>References:</p>
<p><a href="https://arxiv.org/abs/1608.00060" class="uri">https://arxiv.org/abs/1608.00060</a></p>
<p><a href="https://www.amazon.com/Business-Data-Science-Combining-Accelerate/dp/1260452778" class="uri">https://www.amazon.com/Business-Data-Science-Combining-Accelerate/dp/1260452778</a></p>
<p>The code is based on the book.</p>
<div id="partially-linear-iv-model" class="section level2" number="20.1">
<h2><span class="header-section-number">20.1</span> Partially Linear IV Model</h2>
<p>We consider the partially linear structural equation model:
<span class="math display">\[\begin{eqnarray}
 &amp;  Y - D\theta_0 = g_0(X) + \zeta,  &amp; E[\zeta \mid Z,X]= 0,\\
  &amp; Z = m_0(X) +  V,   &amp;  E[V \mid X] = 0. 
\end{eqnarray}\]</span></p>
<p>Note that this model is not a regression model unless <span class="math inline">\(Z=D\)</span>. The model is a canonical
model in causal inference, going back to P. Wright’s work on IV methods for estimaing demand/supply equations, with the modern difference being that <span class="math inline">\(g_0\)</span> and <span class="math inline">\(m_0\)</span> are nonlinear, potentially complicated functions of high-dimensional <span class="math inline">\(X\)</span>.</p>
<p>The idea of this model is that there is a structural or causal relation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span>, captured by <span class="math inline">\(\theta_0\)</span>, and <span class="math inline">\(g_0(X) + \zeta\)</span> is the stochastic error, partly explained by covariates <span class="math inline">\(X\)</span>. <span class="math inline">\(V\)</span> and <span class="math inline">\(\zeta\)</span> are stochastic errors that are not explained by <span class="math inline">\(X\)</span>. Since <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span> are jointly determined, we need an external factor, commonly referred to as an instrument, <span class="math inline">\(Z\)</span> to create exogenous variation
in <span class="math inline">\(D\)</span>. Note that <span class="math inline">\(Z\)</span> should affect <span class="math inline">\(D\)</span>. The <span class="math inline">\(X\)</span> here serve again as confounding factors, so we can think of variation in <span class="math inline">\(Z\)</span> as being exogenous only conditional on <span class="math inline">\(X\)</span>.</p>
<p>The causal DAG this model corresponds to is given by:
<span class="math display">\[
Z \to D,  X \to (Y, Z, D),  L \to (Y,D),
\]</span>
where <span class="math inline">\(L\)</span> is the latent confounder affecting both <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span>, but not <span class="math inline">\(Z\)</span>.</p>
<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
</style>
</div>
<div id="example" class="section level2" number="20.2">
<h2><span class="header-section-number">20.2</span> Example</h2>
<p>A simple contextual example is from biostatistics, where <span class="math inline">\(Y\)</span> is a health outcome and <span class="math inline">\(D\)</span> is indicator of smoking. Thus, <span class="math inline">\(\theta_0\)</span> is captures the effect of smoking on health. Health outcome <span class="math inline">\(Y\)</span> and smoking behavior <span class="math inline">\(D\)</span> are treated as being jointly determined. <span class="math inline">\(X\)</span> represents patient characteristics, and <span class="math inline">\(Z\)</span> could be a doctor’s advice not to smoke (or another behavioral treatment) that may affect the outcome <span class="math inline">\(Y\)</span> only through shifting the behavior <span class="math inline">\(D\)</span>, conditional on characteristics <span class="math inline">\(X\)</span>.</p>
</div>
<div id="plivm-in-residualized-form" class="section level2" number="20.3">
<h2><span class="header-section-number">20.3</span> PLIVM in Residualized Form</h2>
<p>The PLIV model above can be rewritten in the following residualized form:
<span class="math display">\[
  \tilde Y = \tilde D \theta_0 + \zeta,   \quad  E[\zeta \mid V,X]= 0,
\]</span>
where
<span class="math display">\[
 \tilde Y = (Y- \ell_0(X)),  \quad \ell_0(X) = E[Y \mid X] \\
   \tilde D = (D - r_0(X)), \quad r_0(X) = E[D \mid X] \\
   \tilde Z = (Z- m_0(X)), \quad m_0(X) = E[Z \mid X].
\]</span>
The tilded variables above represent original variables after taking out or “partialling out”
the effect of <span class="math inline">\(X\)</span>. Note that <span class="math inline">\(\theta_0\)</span> is identified from this equation if <span class="math inline">\(V\)</span>
and <span class="math inline">\(U\)</span> have non-zero correlation, which automatically means that <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>
must have non-zero variation.</p>
</div>
<div id="dml-for-pliv-model" class="section level2" number="20.4">
<h2><span class="header-section-number">20.4</span> DML for PLIV Model</h2>
<p>Given identification, DML proceeds as follows</p>
<p>Compute the estimates <span class="math inline">\(\hat \ell_0\)</span>, <span class="math inline">\(\hat r_0\)</span>, and <span class="math inline">\(\hat m_0\)</span> , which amounts
to solving the three problems of predicting <span class="math inline">\(Y\)</span>, <span class="math inline">\(D\)</span>, and <span class="math inline">\(Z\)</span> using
<span class="math inline">\(X\)</span>, using any generic ML method, giving us estimated residuals
<span class="math display">\[
\tilde Y = Y - \hat \ell_0(X), \\ \tilde D= D - \hat r_0(X), \\ \tilde Z = Z- \hat m_0(X).
\]</span>
The estimates should be of a cross-validated form, as detailed in the algorithm below.</p>
<p>Estimate <span class="math inline">\(\theta_0\)</span> by the the intstrumental
variable regression of <span class="math inline">\(\tilde Y\)</span> on <span class="math inline">\(\tilde D\)</span> using <span class="math inline">\(\tilde Z\)</span> as an instrument.
Use the conventional inference for the IV regression estimator, ignoring
the estimation error in these residuals.</p>
<p>The reason we work with this residualized form is that it eliminates the bias
arising when solving the prediction problem in stage 1. The role of cross-validation
is to avoid another source of bias due to potential overfitting.</p>
<p>The estimator is adaptive,
in the sense that the first stage estimation errors do not affect the second
stage errors.</p>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;hdm&quot;)</span></span>
<span id="cb1-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;AER&quot;)</span></span>
<span id="cb1-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;randomForest&quot;)</span></span>
<span id="cb1-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(AER)  <span class="co">#applied econometrics library</span></span>
<span id="cb1-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)  <span class="co">#random Forest library</span></span>
<span id="cb1-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hdm) <span class="co">#high-dimensional econometrics library</span></span>
<span id="cb1-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet) <span class="co">#glm net</span></span></code></pre></div>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import relevant packages</span></span>
<span id="cb2-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb2-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hdmpy</span>
<span id="cb2-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb2-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyreadr</span>
<span id="cb2-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> patsy</span>
<span id="cb2-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> linearmodels.iv <span class="im">import</span> IV2SLS</span>
<span id="cb2-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tools <span class="im">import</span> add_constant</span>
<span id="cb2-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb2-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2</span>
<span id="cb2-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb2-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb2-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb2-16" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&quot;ignore&quot;</span>)</span></code></pre></div>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML for PLIVM</span></span>
<span id="cb3-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-3" aria-hidden="true" tabindex="-1"></a>DML2.for.PLIVM <span class="ot">&lt;-</span> <span class="cf">function</span>(x, d, z, y, dreg, yreg, zreg, <span class="at">nfold=</span><span class="dv">2</span>) {</span>
<span id="cb3-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># this implements DML2 algorithm, where there moments are estimated via DML, before constructing</span></span>
<span id="cb3-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># the pooled estimate of theta randomly split data into folds</span></span>
<span id="cb3-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-6" aria-hidden="true" tabindex="-1"></a>  nobs <span class="ot">&lt;-</span> <span class="fu">nrow</span>(x)</span>
<span id="cb3-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-7" aria-hidden="true" tabindex="-1"></a>  foldid <span class="ot">&lt;-</span> <span class="fu">rep.int</span>(<span class="dv">1</span><span class="sc">:</span>nfold,<span class="at">times =</span> <span class="fu">ceiling</span>(nobs<span class="sc">/</span>nfold))[<span class="fu">sample.int</span>(nobs)]</span>
<span id="cb3-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-8" aria-hidden="true" tabindex="-1"></a>  I <span class="ot">&lt;-</span> <span class="fu">split</span>(<span class="dv">1</span><span class="sc">:</span>nobs, foldid)</span>
<span id="cb3-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># create residualized objects to fill</span></span>
<span id="cb3-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-10" aria-hidden="true" tabindex="-1"></a>  ytil <span class="ot">&lt;-</span> dtil <span class="ot">&lt;-</span> ztil<span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nobs)</span>
<span id="cb3-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># obtain cross-fitted residuals</span></span>
<span id="cb3-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;fold: &quot;</span>)</span>
<span id="cb3-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(b <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(I)){</span>
<span id="cb3-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-14" aria-hidden="true" tabindex="-1"></a>    dfit <span class="ot">&lt;-</span> <span class="fu">dreg</span>(x[<span class="sc">-</span>I[[b]],], d[<span class="sc">-</span>I[[b]]])  <span class="co">#take a fold out</span></span>
<span id="cb3-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-15" aria-hidden="true" tabindex="-1"></a>    zfit <span class="ot">&lt;-</span> <span class="fu">zreg</span>(x[<span class="sc">-</span>I[[b]],], z[<span class="sc">-</span>I[[b]]])  <span class="co">#take a fold out</span></span>
<span id="cb3-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-16" aria-hidden="true" tabindex="-1"></a>    yfit <span class="ot">&lt;-</span> <span class="fu">yreg</span>(x[<span class="sc">-</span>I[[b]],], y[<span class="sc">-</span>I[[b]]])  <span class="co"># take a folot out</span></span>
<span id="cb3-17"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-17" aria-hidden="true" tabindex="-1"></a>    dhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(dfit, x[I[[b]],], <span class="at">type=</span><span class="st">&quot;response&quot;</span>)  <span class="co">#predict the fold out</span></span>
<span id="cb3-18"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-18" aria-hidden="true" tabindex="-1"></a>    zhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(zfit, x[I[[b]],], <span class="at">type=</span><span class="st">&quot;response&quot;</span>)  <span class="co">#predict the fold out</span></span>
<span id="cb3-19"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-19" aria-hidden="true" tabindex="-1"></a>    yhat <span class="ot">&lt;-</span> <span class="fu">predict</span>(yfit, x[I[[b]],], <span class="at">type=</span><span class="st">&quot;response&quot;</span>)  <span class="co">#predict the fold out</span></span>
<span id="cb3-20"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-20" aria-hidden="true" tabindex="-1"></a>    dtil[I[[b]]] <span class="ot">&lt;-</span> (d[I[[b]]] <span class="sc">-</span> dhat) <span class="co">#record residual</span></span>
<span id="cb3-21"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-21" aria-hidden="true" tabindex="-1"></a>    ztil[I[[b]]] <span class="ot">&lt;-</span> (z[I[[b]]] <span class="sc">-</span> zhat) <span class="co">#record residual</span></span>
<span id="cb3-22"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-22" aria-hidden="true" tabindex="-1"></a>    ytil[I[[b]]] <span class="ot">&lt;-</span> (y[I[[b]]] <span class="sc">-</span> yhat) <span class="co">#record residial</span></span>
<span id="cb3-23"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cat</span>(b,<span class="st">&quot; &quot;</span>)</span>
<span id="cb3-24"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">print</span>(<span class="fu">dim</span>( x[<span class="sc">-</span>I[[b]],]))</span>
<span id="cb3-25"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-25" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb3-26"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-26" aria-hidden="true" tabindex="-1"></a>  ivfit<span class="ot">=</span> <span class="fu">tsls</span>(<span class="at">y=</span>ytil,<span class="at">d=</span>dtil, <span class="at">x=</span><span class="cn">NULL</span>, <span class="at">z=</span>ztil, <span class="at">intercept=</span><span class="cn">FALSE</span>)</span>
<span id="cb3-27"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-27" aria-hidden="true" tabindex="-1"></a>  coef.est <span class="ot">&lt;-</span>  ivfit<span class="sc">$</span>coef          <span class="co">#extract coefficient </span></span>
<span id="cb3-28"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-28" aria-hidden="true" tabindex="-1"></a>  se <span class="ot">&lt;-</span>  ivfit<span class="sc">$</span>se                  <span class="co">#record standard error</span></span>
<span id="cb3-29"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st">coef (se) = %g (%g)</span><span class="sc">\n</span><span class="st">&quot;</span>, coef.est , se))</span>
<span id="cb3-30"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>( <span class="fu">list</span>(<span class="at">coef.est =</span>coef.est , <span class="at">se=</span>se, <span class="at">dtil=</span>dtil, <span class="at">ytil=</span>ytil, <span class="at">ztil=</span>ztil) )</span>
<span id="cb3-31"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb3-31" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> DML2_for_PLIVM(x, d, z , y, dreg, yreg, zreg, nfold <span class="op">=</span> <span class="dv">2</span> ):</span>
<span id="cb4-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Num ob observations</span></span>
<span id="cb4-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-4" aria-hidden="true" tabindex="-1"></a>    nobs <span class="op">=</span> x.shape[<span class="dv">0</span>]</span>
<span id="cb4-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define folds indices </span></span>
<span id="cb4-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-7" aria-hidden="true" tabindex="-1"></a>    list_1 <span class="op">=</span> [<span class="op">*</span><span class="bu">range</span>(<span class="dv">0</span>, nfold, <span class="dv">1</span>)]<span class="op">*</span>nobs</span>
<span id="cb4-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-8" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> np.random.choice(nobs,nobs, replace<span class="op">=</span><span class="va">False</span>).tolist()</span>
<span id="cb4-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-9" aria-hidden="true" tabindex="-1"></a>    foldid <span class="op">=</span> [list_1[index] <span class="cf">for</span> index <span class="kw">in</span> sample]</span>
<span id="cb4-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create split function(similar to R)</span></span>
<span id="cb4-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> split(x, f):</span>
<span id="cb4-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-13" aria-hidden="true" tabindex="-1"></a>        count <span class="op">=</span> <span class="bu">max</span>(f) <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb4-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">tuple</span>( <span class="bu">list</span>(itertools.compress(x, (el <span class="op">==</span> i <span class="cf">for</span> el <span class="kw">in</span> f))) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(count) ) </span>
<span id="cb4-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Split observation indices into folds </span></span>
<span id="cb4-17"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-17" aria-hidden="true" tabindex="-1"></a>    list_2 <span class="op">=</span> [<span class="op">*</span><span class="bu">range</span>(<span class="dv">0</span>, nobs, <span class="dv">1</span>)]</span>
<span id="cb4-18"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-18" aria-hidden="true" tabindex="-1"></a>    I <span class="op">=</span> split(list_2, foldid)</span>
<span id="cb4-19"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-20"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create array to save errors </span></span>
<span id="cb4-21"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-21" aria-hidden="true" tabindex="-1"></a>    dtil <span class="op">=</span> np.zeros( <span class="bu">len</span>(x) ).reshape( <span class="bu">len</span>(x) , <span class="dv">1</span> )</span>
<span id="cb4-22"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-22" aria-hidden="true" tabindex="-1"></a>    ytil <span class="op">=</span> np.zeros( <span class="bu">len</span>(x) ).reshape( <span class="bu">len</span>(x) , <span class="dv">1</span> )</span>
<span id="cb4-23"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-23" aria-hidden="true" tabindex="-1"></a>    ztil <span class="op">=</span> np.zeros( <span class="bu">len</span>(x) ).reshape( <span class="bu">len</span>(x) , <span class="dv">1</span> )</span>
<span id="cb4-24"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-25"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-25" aria-hidden="true" tabindex="-1"></a>    total_modelos <span class="op">=</span> []</span>
<span id="cb4-26"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-27"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-27" aria-hidden="true" tabindex="-1"></a>    total_sample <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-28"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop to save results</span></span>
<span id="cb4-29"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> b <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(I)):</span>
<span id="cb4-30"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-31"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Split data - index to keep are in mask as booleans</span></span>
<span id="cb4-32"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-32" aria-hidden="true" tabindex="-1"></a>        include_idx <span class="op">=</span> <span class="bu">set</span>(I[b])  <span class="co">#Here should go I[b] Set is more efficient, but doesn&#39;t reorder your elements if that is desireable</span></span>
<span id="cb4-33"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-33" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> np.array([(i <span class="kw">in</span> include_idx) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(x))])</span>
<span id="cb4-34"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Lasso regression, excluding folds selected </span></span>
<span id="cb4-36"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-36" aria-hidden="true" tabindex="-1"></a>        dfit <span class="op">=</span> dreg(x[<span class="op">~</span>mask,], d[<span class="op">~</span>mask,])</span>
<span id="cb4-37"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-37" aria-hidden="true" tabindex="-1"></a>        zfit <span class="op">=</span> zreg(x[<span class="op">~</span>mask,], z[<span class="op">~</span>mask,])</span>
<span id="cb4-38"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-38" aria-hidden="true" tabindex="-1"></a>        yfit <span class="op">=</span> yreg(x[<span class="op">~</span>mask,], y[<span class="op">~</span>mask,])</span>
<span id="cb4-39"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># predict estimates using the </span></span>
<span id="cb4-41"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-41" aria-hidden="true" tabindex="-1"></a>        dhat <span class="op">=</span> dfit.predict( x[mask,] )</span>
<span id="cb4-42"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-42" aria-hidden="true" tabindex="-1"></a>        zhat <span class="op">=</span> zfit.predict( x[mask,] )</span>
<span id="cb4-43"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-43" aria-hidden="true" tabindex="-1"></a>        yhat <span class="op">=</span> yfit.predict( x[mask,] )</span>
<span id="cb4-44"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-44" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-45"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-45" aria-hidden="true" tabindex="-1"></a>        <span class="co"># save errors  </span></span>
<span id="cb4-46"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-46" aria-hidden="true" tabindex="-1"></a>        dtil[mask] <span class="op">=</span> d[mask,] <span class="op">-</span> dhat.reshape( <span class="bu">len</span>(I[b]) , <span class="dv">1</span> )</span>
<span id="cb4-47"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-47" aria-hidden="true" tabindex="-1"></a>        ztil[mask] <span class="op">=</span> z[mask,] <span class="op">-</span> zhat.reshape( <span class="bu">len</span>(I[b]) , <span class="dv">1</span> )</span>
<span id="cb4-48"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-48" aria-hidden="true" tabindex="-1"></a>        ytil[mask] <span class="op">=</span> y[mask,] <span class="op">-</span> yhat.reshape( <span class="bu">len</span>(I[b]) , <span class="dv">1</span> )</span>
<span id="cb4-49"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-50"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-50" aria-hidden="true" tabindex="-1"></a>        total_modelos.append( dfit )</span>
<span id="cb4-51"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-52"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(b, <span class="st">&quot; &quot;</span>)</span>
<span id="cb4-53"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-53" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-54"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create dataframe</span></span>
<span id="cb4-55"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-55" aria-hidden="true" tabindex="-1"></a>    ivfit <span class="op">=</span> IV2SLS( exog <span class="op">=</span> <span class="va">None</span> , endog <span class="op">=</span> dtil , dependent <span class="op">=</span> ytil , instruments <span class="op">=</span> ztil ).fit( cov_type <span class="op">=</span> <span class="st">&#39;unadjusted&#39;</span> ) <span class="co">## unadjusted == homocedastick</span></span>
<span id="cb4-56"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-56" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb4-57"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-57" aria-hidden="true" tabindex="-1"></a>    <span class="co"># OLS clustering at the County level</span></span>
<span id="cb4-58"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-58" aria-hidden="true" tabindex="-1"></a>    coef_est <span class="op">=</span>  ivfit.params[<span class="dv">0</span>]</span>
<span id="cb4-59"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-59" aria-hidden="true" tabindex="-1"></a>    se <span class="op">=</span> ivfit.std_errors[<span class="dv">0</span>]</span>
<span id="cb4-60"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-60" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>( <span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss"> Coefficient (se) = </span><span class="sc">{</span>coef_est<span class="sc">}</span><span class="ss"> (</span><span class="sc">{se}</span><span class="ss">)&quot;</span> )</span>
<span id="cb4-61"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-61" aria-hidden="true" tabindex="-1"></a>    Final_result <span class="op">=</span> { <span class="st">&#39;coef_est&#39;</span> : coef_est , <span class="st">&#39;se&#39;</span> : se , <span class="st">&#39;dtil&#39;</span> : dtil , <span class="st">&#39;ytil&#39;</span> : ytil , <span class="st">&#39;ztil&#39;</span> : ztil , <span class="st">&#39;modelos&#39;</span> : total_modelos }</span>
<span id="cb4-62"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-62" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb4-63"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Final_result</span>
<span id="cb4-64"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb4-64" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
</div>
</div>
<hr />
</div>
<div id="emprical-example-acemoglu-jonsohn-robinson-aer." class="section level2" number="20.5">
<h2><span class="header-section-number">20.5</span> Emprical Example: Acemoglu, Jonsohn, Robinson (AER).</h2>
<ul>
<li>Y is log GDP;</li>
<li>D is a measure of Protection from Expropriation, a proxy for
quality of insitutions;</li>
<li>Z is the log of Settler’s mortality;</li>
<li>W are geographical variables (latitude, latitude squared, continent dummies as well as interactions)</li>
</ul>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(AJR)</span>
<span id="cb5-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> AJR<span class="sc">$</span>GDP; </span>
<span id="cb5-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-4" aria-hidden="true" tabindex="-1"></a>d <span class="ot">=</span> AJR<span class="sc">$</span>Exprop; </span>
<span id="cb5-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-5" aria-hidden="true" tabindex="-1"></a>z <span class="ot">=</span> AJR<span class="sc">$</span>logMort</span>
<span id="cb5-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-6" aria-hidden="true" tabindex="-1"></a>xraw<span class="ot">=</span> <span class="fu">model.matrix</span>(<span class="sc">~</span> Latitude<span class="sc">+</span> Africa<span class="sc">+</span>Asia <span class="sc">+</span> Namer <span class="sc">+</span> Samer, <span class="at">data=</span>AJR)</span>
<span id="cb5-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-7" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="fu">model.matrix</span>(<span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> (Latitude <span class="sc">+</span> Latitude2 <span class="sc">+</span> Africa <span class="sc">+</span> </span>
<span id="cb5-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-8" aria-hidden="true" tabindex="-1"></a>                           Asia <span class="sc">+</span> Namer <span class="sc">+</span> Samer)<span class="sc">^</span><span class="dv">2</span>, <span class="at">data=</span>AJR)</span>
<span id="cb5-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(x)</span></code></pre></div>
<pre><code>## [1] 64 21</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-1" aria-hidden="true" tabindex="-1"></a>rdata_read <span class="op">=</span> pyreadr.read_r(<span class="st">&quot;data/ajr.Rdata&quot;</span>)</span>
<span id="cb7-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-2" aria-hidden="true" tabindex="-1"></a>AJR <span class="op">=</span> rdata_read[ <span class="st">&#39;AJR&#39;</span> ]</span>
<span id="cb7-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> AJR[[<span class="st">&#39;GDP&#39;</span>]].to_numpy()</span>
<span id="cb7-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-5" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> AJR[[<span class="st">&#39;Exprop&#39;</span>]].to_numpy()</span>
<span id="cb7-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-6" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> AJR[[<span class="st">&#39;logMort&#39;</span>]].to_numpy()</span>
<span id="cb7-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-8" aria-hidden="true" tabindex="-1"></a>xraw_formula <span class="op">=</span>  <span class="st">&quot; GDP ~ Latitude+ Africa+Asia + Namer + Samer&quot;</span></span>
<span id="cb7-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-9" aria-hidden="true" tabindex="-1"></a>x_formula <span class="op">=</span> <span class="st">&quot; GDP ~ -1 + ( Latitude + Latitude2 + Africa + Asia + Namer + Samer ) ** 2&quot;</span></span>
<span id="cb7-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-11" aria-hidden="true" tabindex="-1"></a>y_model, xraw_dframe <span class="op">=</span> patsy.dmatrices( xraw_formula, AJR , return_type<span class="op">=</span><span class="st">&#39;matrix&#39;</span>)</span>
<span id="cb7-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-12" aria-hidden="true" tabindex="-1"></a>y_model, x_dframe <span class="op">=</span> patsy.dmatrices( x_formula, AJR , return_type<span class="op">=</span><span class="st">&#39;matrix&#39;</span>)</span>
<span id="cb7-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-14" aria-hidden="true" tabindex="-1"></a>xraw <span class="op">=</span> np.asarray( xraw_dframe , dtype <span class="op">=</span> np.float64 )</span>
<span id="cb7-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-15" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.asarray( x_dframe , dtype <span class="op">=</span> np.float64)</span>
<span id="cb7-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb7-16" aria-hidden="true" tabindex="-1"></a>x.shape</span></code></pre></div>
<pre><code>## (64, 21)</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with Random Forest</span></span>
<span id="cb9-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st"> DML with Random Forest </span><span class="sc">\n</span><span class="st">&quot;</span>))</span></code></pre></div>
<pre><code>## 
##  DML with Random Forest</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with Random Forest</span></span>
<span id="cb11-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st"> DML with Random Forest </span><span class="ch">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  DML with Random Forest</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with Random Forest</span></span>
<span id="cb13-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb13-2" aria-hidden="true" tabindex="-1"></a>dreg <span class="ot">&lt;-</span> <span class="cf">function</span>(x,d){ <span class="fu">randomForest</span>(x, d) }  <span class="co">#ML method=Forest</span></span>
<span id="cb13-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb13-3" aria-hidden="true" tabindex="-1"></a>yreg <span class="ot">&lt;-</span> <span class="cf">function</span>(x,y){ <span class="fu">randomForest</span>(x, y) }  <span class="co">#ML method=Forest</span></span>
<span id="cb13-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb13-4" aria-hidden="true" tabindex="-1"></a>zreg<span class="ot">&lt;-</span>  <span class="cf">function</span>(x,z){ <span class="fu">randomForest</span>(x, z)}  <span class="co">#ML method=Forest </span></span>
<span id="cb13-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb13-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb13-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb13-7" aria-hidden="true" tabindex="-1"></a>DML2.RF <span class="ot">=</span> <span class="fu">DML2.for.PLIVM</span>(xraw, d, z, y, dreg, yreg, zreg, <span class="at">nfold=</span><span class="dv">20</span>)</span></code></pre></div>
<pre><code>## fold: 1  [1] 60  6
## 2  [1] 60  6
## 3  [1] 60  6
## 4  [1] 60  6
## 5  [1] 61  6
## 6  [1] 61  6
## 7  [1] 61  6
## 8  [1] 61  6
## 9  [1] 61  6
## 10  [1] 61  6
## 11  [1] 61  6
## 12  [1] 61  6
## 13  [1] 61  6
## 14  [1] 61  6
## 15  [1] 61  6
## 16  [1] 61  6
## 17  [1] 61  6
## 18  [1] 61  6
## 19  [1] 61  6
## 20  [1] 61  6
## 
## coef (se) = 0.885958 (0.325226)</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with Random Forest</span></span>
<span id="cb15-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dreg( x_1 , d_1 ):</span>
<span id="cb15-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> d_1 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> ( d_1.dtype <span class="op">!=</span> <span class="bu">str</span> ):</span>
<span id="cb15-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-5" aria-hidden="true" tabindex="-1"></a>        mtry1 <span class="op">=</span> <span class="bu">max</span>( [ np.<span class="bu">round</span>( ( x_1.shape[ <span class="dv">1</span> ]<span class="op">/</span><span class="dv">3</span> ) ) , <span class="dv">1</span> ] ).astype(<span class="bu">int</span>)</span>
<span id="cb15-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-7" aria-hidden="true" tabindex="-1"></a>        mtry1 <span class="op">=</span> np.<span class="bu">round</span>( np.sqrt( x_1.shape[ <span class="dv">1</span> ] ) ).astype(<span class="bu">int</span>)</span>
<span id="cb15-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> d_1 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> ( d_1.dtype <span class="op">!=</span> <span class="bu">str</span> ):</span>
<span id="cb15-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-10" aria-hidden="true" tabindex="-1"></a>        nodesize1 <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb15-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-12" aria-hidden="true" tabindex="-1"></a>        nodesize1 <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb15-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-14" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> RandomForestRegressor( random_state <span class="op">=</span> <span class="dv">0</span> , n_estimators <span class="op">=</span> <span class="dv">500</span> , max_features <span class="op">=</span> mtry1 , n_jobs <span class="op">=</span> <span class="dv">4</span> , min_samples_leaf <span class="op">=</span> nodesize1 ).fit( x_1 , d_1 )</span>
<span id="cb15-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb15-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> yreg( x_1 , y_1 ):</span>
<span id="cb15-18"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> y_1 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> ( y_1.dtype <span class="op">!=</span> <span class="bu">str</span> ):</span>
<span id="cb15-19"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-19" aria-hidden="true" tabindex="-1"></a>        mtry1 <span class="op">=</span> <span class="bu">max</span>( [ np.<span class="bu">round</span>( ( x_1.shape[ <span class="dv">1</span> ]<span class="op">/</span><span class="dv">3</span> ) ) , <span class="dv">1</span> ] ).astype(<span class="bu">int</span>)</span>
<span id="cb15-20"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-21"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-21" aria-hidden="true" tabindex="-1"></a>        mtry1 <span class="op">=</span> np.<span class="bu">round</span>( np.sqrt( x_1.shape[ <span class="dv">1</span> ] ) ).astype(<span class="bu">int</span>)</span>
<span id="cb15-22"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> y_1 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> ( y_1.dtype <span class="op">!=</span> <span class="bu">str</span> ):</span>
<span id="cb15-24"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-24" aria-hidden="true" tabindex="-1"></a>        nodesize1 <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb15-25"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-26"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-26" aria-hidden="true" tabindex="-1"></a>        nodesize1 <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb15-27"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-28"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-28" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> RandomForestRegressor( random_state <span class="op">=</span> <span class="dv">0</span> , n_estimators <span class="op">=</span> <span class="dv">500</span> , max_features <span class="op">=</span> mtry1 , n_jobs <span class="op">=</span> <span class="dv">4</span> , min_samples_leaf <span class="op">=</span> nodesize1 ).fit( x_1, y_1 )</span>
<span id="cb15-29"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb15-30"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zreg( x_1 , z_1 ):</span>
<span id="cb15-32"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-33"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> z_1 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> ( z_1.dtype <span class="op">!=</span> <span class="bu">str</span> ):</span>
<span id="cb15-34"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-34" aria-hidden="true" tabindex="-1"></a>        mtry1 <span class="op">=</span> <span class="bu">max</span>( [ np.<span class="bu">round</span>( ( x_1.shape[ <span class="dv">1</span> ]<span class="op">/</span><span class="dv">3</span> ) ) , <span class="dv">1</span> ] ).astype(<span class="bu">int</span>)</span>
<span id="cb15-35"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-36"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-36" aria-hidden="true" tabindex="-1"></a>        mtry1 <span class="op">=</span> np.<span class="bu">round</span>( np.sqrt( x_1.shape[ <span class="dv">1</span> ] ) ).astype(<span class="bu">int</span>)</span>
<span id="cb15-37"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> z_1 <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> ( z_1.dtype <span class="op">!=</span> <span class="bu">str</span> ):</span>
<span id="cb15-39"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-39" aria-hidden="true" tabindex="-1"></a>        nodesize1 <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb15-40"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb15-41"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-41" aria-hidden="true" tabindex="-1"></a>        nodesize1 <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb15-42"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-43"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-43" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> RandomForestRegressor( random_state <span class="op">=</span> <span class="dv">0</span> , n_estimators <span class="op">=</span> <span class="dv">500</span> , max_features <span class="op">=</span> mtry1 , n_jobs <span class="op">=</span> <span class="dv">4</span> , min_samples_leaf <span class="op">=</span> nodesize1 ).fit( x_1, z_1 )</span>
<span id="cb15-44"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb15-45"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-46"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-46" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1</span>)</span>
<span id="cb15-47"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb15-47" aria-hidden="true" tabindex="-1"></a>DML2_RF <span class="op">=</span> DML2_for_PLIVM(xraw, d, z, y, dreg, yreg, zreg, nfold<span class="op">=</span><span class="dv">20</span>)</span></code></pre></div>
<pre><code>## 0  
## 1  
## 2  
## 3  
## 4  
## 5  
## 6  
## 7  
## 8  
## 9  
## 10  
## 11  
## 12  
## 13  
## 14  
## 15  
## 16  
## 17  
## 18  
## 19  
## 
##  Coefficient (se) = 0.793239728272677 (0.2677841754799799)</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with PostLasso</span></span>
<span id="cb17-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">&quot;</span><span class="sc">\n</span><span class="st"> DML with Post-Lasso </span><span class="sc">\n</span><span class="st">&quot;</span>))</span></code></pre></div>
<pre><code>## 
##  DML with Post-Lasso</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with PostLasso</span></span>
<span id="cb19-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="st">&quot;</span><span class="ch">\n</span><span class="st"> DML with Post-Lasso </span><span class="ch">\n</span><span class="st">&quot;</span> )</span></code></pre></div>
<pre><code>## 
##  DML with Post-Lasso</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with PostLasso</span></span>
<span id="cb21-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb21-2" aria-hidden="true" tabindex="-1"></a>dreg <span class="ot">&lt;-</span> <span class="cf">function</span>(x,d){ <span class="fu">rlasso</span>(x, d) }  <span class="co">#ML method=lasso</span></span>
<span id="cb21-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb21-3" aria-hidden="true" tabindex="-1"></a>yreg <span class="ot">&lt;-</span> <span class="cf">function</span>(x,y){ <span class="fu">rlasso</span>(x, y) }  <span class="co">#ML method=lasso</span></span>
<span id="cb21-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb21-4" aria-hidden="true" tabindex="-1"></a>zreg<span class="ot">&lt;-</span>  <span class="cf">function</span>(x,z){ <span class="fu">rlasso</span>(x, z)}  <span class="co">#ML method=lasso </span></span>
<span id="cb21-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb21-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb21-7" aria-hidden="true" tabindex="-1"></a>DML2.lasso <span class="ot">=</span> <span class="fu">DML2.for.PLIVM</span>(x, d, z, y, dreg, yreg, zreg, <span class="at">nfold=</span><span class="dv">20</span>)</span></code></pre></div>
<pre><code>## fold: 1  [1] 60 21
## 2  [1] 60 21
## 3  [1] 60 21
## 4  [1] 60 21
## 5  [1] 61 21
## 6  [1] 61 21
## 7  [1] 61 21
## 8  [1] 61 21
## 9  [1] 61 21
## 10  [1] 61 21
## 11  [1] 61 21
## 12  [1] 61 21
## 13  [1] 61 21
## 14  [1] 61 21
## 15  [1] 61 21
## 16  [1] 61 21
## 17  [1] 61 21
## 18  [1] 61 21
## 19  [1] 61 21
## 20  [1] 61 21
## 
## coef (se) = 0.711469 (0.173174)</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML with PostLasso</span></span>
<span id="cb23-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> rlasso_sklearn:</span>
<span id="cb23-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, post ):</span>
<span id="cb23-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.post <span class="op">=</span> post</span>
<span id="cb23-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-6" aria-hidden="true" tabindex="-1"></a>       </span>
<span id="cb23-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit( <span class="va">self</span>, X, Y ):</span>
<span id="cb23-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X <span class="op">=</span> X</span>
<span id="cb23-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.Y <span class="op">=</span> Y</span>
<span id="cb23-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Standarization of X and Y</span></span>
<span id="cb23-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rlasso_model <span class="op">=</span> hdmpy.rlasso( X , Y , post <span class="op">=</span> <span class="va">self</span>.post )                </span>
<span id="cb23-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb23-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict( <span class="va">self</span> , X_1 ):</span>
<span id="cb23-17"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.X_1 <span class="op">=</span> X_1</span>
<span id="cb23-18"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-18" aria-hidden="true" tabindex="-1"></a>        beta <span class="op">=</span> <span class="va">self</span>.rlasso_model.est[<span class="st">&#39;coefficients&#39;</span>].to_numpy()</span>
<span id="cb23-19"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-20"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> beta.<span class="bu">sum</span>() <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb23-21"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-21" aria-hidden="true" tabindex="-1"></a>            prediction <span class="op">=</span> np.repeat( <span class="va">self</span>.rlasso_model.est[<span class="st">&#39;intercept&#39;</span>] , <span class="va">self</span>.X_1.shape[<span class="dv">0</span>] )</span>
<span id="cb23-22"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb23-23"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb23-24"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-24" aria-hidden="true" tabindex="-1"></a>            prediction <span class="op">=</span> ( add_constant( <span class="va">self</span>.X_1 , has_constant <span class="op">=</span> <span class="st">&#39;add&#39;</span>) <span class="op">@</span> beta ).flatten()</span>
<span id="cb23-25"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-25" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb23-26"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> prediction</span>
<span id="cb23-27"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-29"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> dreg(x, d):</span>
<span id="cb23-30"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-30" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> rlasso_sklearn( post <span class="op">=</span> <span class="va">True</span> ).fit( x , d )</span>
<span id="cb23-31"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb23-32"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-33"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> yreg(x,y):</span>
<span id="cb23-34"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-34" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> rlasso_sklearn( post <span class="op">=</span> <span class="va">True</span> ).fit( x , y )</span>
<span id="cb23-35"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb23-36"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-37"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> zreg(x,z):</span>
<span id="cb23-38"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-38" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> rlasso_sklearn( post <span class="op">=</span> <span class="va">True</span> ).fit( x , z )</span>
<span id="cb23-39"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> result</span>
<span id="cb23-40"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-41" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1</span>)</span>
<span id="cb23-42"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb23-42" aria-hidden="true" tabindex="-1"></a>DML2_lasso <span class="op">=</span> DML2_for_PLIVM(x, d, z, y, dreg, yreg, zreg, nfold <span class="op">=</span> <span class="dv">20</span> )</span></code></pre></div>
<pre><code>## 0  
## 1  
## 2  
## 3  
## 4  
## 5  
## 6  
## 7  
## 8  
## 9  
## 10  
## 11  
## 12  
## 13  
## 14  
## 15  
## 16  
## 17  
## 18  
## 19  
## 
##  Coefficient (se) = 0.7816842974934118 (0.10243297292202395)</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare Forest vs Lasso</span></span>
<span id="cb25-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-3" aria-hidden="true" tabindex="-1"></a>comp.tab<span class="ot">=</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb25-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-4" aria-hidden="true" tabindex="-1"></a>comp.tab[<span class="dv">1</span>,] <span class="ot">=</span> <span class="fu">c</span>( <span class="fu">sqrt</span>(<span class="fu">mean</span>((DML2.RF<span class="sc">$</span>ytil)<span class="sc">^</span><span class="dv">2</span>)),  <span class="fu">sqrt</span>(<span class="fu">mean</span>((DML2.lasso<span class="sc">$</span>ytil)<span class="sc">^</span><span class="dv">2</span>)) )</span>
<span id="cb25-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-5" aria-hidden="true" tabindex="-1"></a>comp.tab[<span class="dv">2</span>,] <span class="ot">=</span> <span class="fu">c</span>( <span class="fu">sqrt</span>(<span class="fu">mean</span>((DML2.RF<span class="sc">$</span>dtil)<span class="sc">^</span><span class="dv">2</span>)),  <span class="fu">sqrt</span>(<span class="fu">mean</span>((DML2.lasso<span class="sc">$</span>dtil)<span class="sc">^</span><span class="dv">2</span>)) )</span>
<span id="cb25-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-6" aria-hidden="true" tabindex="-1"></a>comp.tab[<span class="dv">3</span>,] <span class="ot">=</span> <span class="fu">c</span>( <span class="fu">sqrt</span>(<span class="fu">mean</span>((DML2.RF<span class="sc">$</span>ztil)<span class="sc">^</span><span class="dv">2</span>)),  <span class="fu">sqrt</span>(<span class="fu">mean</span>((DML2.lasso<span class="sc">$</span>ztil)<span class="sc">^</span><span class="dv">2</span>)) )</span>
<span id="cb25-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(comp.tab) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;RMSE for Y:&quot;</span>, <span class="st">&quot;RMSE for D:&quot;</span>, <span class="st">&quot;RMSE for Z:&quot;</span>)</span>
<span id="cb25-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(comp.tab) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;RF&quot;</span>, <span class="st">&quot;LASSO&quot;</span>)</span>
<span id="cb25-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(comp.tab, <span class="at">digits=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>##                RF LASSO
## RMSE for Y: 0.775 0.871
## RMSE for D: 1.275 1.544
## RMSE for Z: 0.912 1.046</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare Forest vs Lasso</span></span>
<span id="cb27-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-3" aria-hidden="true" tabindex="-1"></a>comp_tab_numpy <span class="op">=</span> np.zeros( ( <span class="dv">3</span> , <span class="dv">2</span> ) )</span>
<span id="cb27-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-5" aria-hidden="true" tabindex="-1"></a>comp_tab_numpy[ <span class="dv">0</span> , : ] <span class="op">=</span> [ np.sqrt( np.mean( DML2_RF[<span class="st">&#39;ytil&#39;</span>] <span class="op">**</span> <span class="dv">2</span> ) ) , np.sqrt( np.mean( DML2_lasso[<span class="st">&#39;ytil&#39;</span>] <span class="op">**</span> <span class="dv">2</span> ) ) ]</span>
<span id="cb27-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-6" aria-hidden="true" tabindex="-1"></a>comp_tab_numpy[ <span class="dv">1</span> , : ] <span class="op">=</span> [ np.sqrt( np.mean( DML2_RF[<span class="st">&#39;dtil&#39;</span>] <span class="op">**</span> <span class="dv">2</span> ) ) , np.sqrt( np.mean( DML2_lasso[<span class="st">&#39;dtil&#39;</span>] <span class="op">**</span> <span class="dv">2</span> ) ) ]</span>
<span id="cb27-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-7" aria-hidden="true" tabindex="-1"></a>comp_tab_numpy[ <span class="dv">2</span> , : ] <span class="op">=</span> [ np.sqrt( np.mean( DML2_RF[<span class="st">&#39;ztil&#39;</span>] <span class="op">**</span> <span class="dv">2</span> ) ) , np.sqrt( np.mean( DML2_lasso[<span class="st">&#39;ztil&#39;</span>] <span class="op">**</span> <span class="dv">2</span> ) ) ]</span>
<span id="cb27-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-8" aria-hidden="true" tabindex="-1"></a>comp_tab <span class="op">=</span> pd.DataFrame( comp_tab_numpy , columns <span class="op">=</span> [ <span class="st">&#39;RF&#39;</span> ,<span class="st">&#39;LASSO&#39;</span> ] , index <span class="op">=</span> [ <span class="st">&quot;RMSE for Y:&quot;</span>, <span class="st">&quot;RMSE for D:&quot;</span>, <span class="st">&quot;RMSE for Z:&quot;</span> ] )</span>
<span id="cb27-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(comp_tab)</span></code></pre></div>
<pre><code>##                    RF     LASSO
## RMSE for Y:  0.793904  1.247203
## RMSE for D:  1.334754  1.838495
## RMSE for Z:  0.934056  1.482012</code></pre>
</div>
</div>
</div>
<div id="examine-if-we-have-weak-instruments" class="section level2" number="20.6">
<h2><span class="header-section-number">20.6</span> Examine if we have weak instruments</h2>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;lfe&quot;)</span></span>
<span id="cb29-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lfe)</span>
<span id="cb29-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">felm</span>(DML2.lasso<span class="sc">$</span>dtil<span class="sc">~</span>DML2.lasso<span class="sc">$</span>ztil), <span class="at">robust=</span>T)</span></code></pre></div>
<pre><code>## 
## Call:
##    felm(formula = DML2.lasso$dtil ~ DML2.lasso$ztil) 
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.1611 -1.0202  0.1249  1.0021  3.0360 
## 
## Coefficients:
##                  Estimate Robust s.e t value Pr(&gt;|t|)   
## (Intercept)      0.000105   0.179497   0.001  0.99954   
## DML2.lasso$ztil -0.587550   0.204111  -2.879  0.00547 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.439 on 62 degrees of freedom
## Multiple R-squared(full model): 0.1584   Adjusted R-squared: 0.1448 
## Multiple R-squared(proj model): 0.1584   Adjusted R-squared: 0.1448 
## F-statistic(full model, *iid*):11.67 on 1 and 62 DF, p-value: 0.001127 
## F-statistic(proj model): 8.286 on 1 and 62 DF, p-value: 0.005475</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sm.OLS( DML2_lasso[ <span class="st">&#39;dtil&#39;</span> ] , DML2_lasso[ <span class="st">&#39;ztil&#39;</span> ] ).fit( cov_type <span class="op">=</span> <span class="st">&#39;HC1&#39;</span>, use_t <span class="op">=</span> <span class="va">True</span> ).summary())</span></code></pre></div>
<pre><code>##                                  OLS Regression Results                                
## =======================================================================================
## Dep. Variable:                      y   R-squared (uncentered):                   0.409
## Model:                            OLS   Adj. R-squared (uncentered):              0.400
## Method:                 Least Squares   F-statistic:                              23.71
## Date:                Wed, 24 Nov 2021   Prob (F-statistic):                    7.87e-06
## Time:                        16:38:38   Log-Likelihood:                         -112.94
## No. Observations:                  64   AIC:                                      227.9
## Df Residuals:                      63   BIC:                                      230.0
## Df Model:                           1                                                  
## Covariance Type:                  HC1                                                  
## ==============================================================================
##                  coef    std err          t      P&gt;|t|      [0.025      0.975]
## ------------------------------------------------------------------------------
## x1            -0.7936      0.163     -4.869      0.000      -1.119      -0.468
## ==============================================================================
## Omnibus:                        0.246   Durbin-Watson:                   1.621
## Prob(Omnibus):                  0.884   Jarque-Bera (JB):                0.400
## Skew:                          -0.122   Prob(JB):                        0.819
## Kurtosis:                       2.699   Cond. No.                         1.00
## ==============================================================================
## 
## Notes:
## [1] R² is computed without centering (uncentered) since the model does not contain a constant.
## [2] Standard Errors are heteroscedasticity robust (HC1)</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">felm</span>(DML2.RF<span class="sc">$</span>dtil<span class="sc">~</span>DML2.RF<span class="sc">$</span>ztil), <span class="at">robust=</span>T)</span></code></pre></div>
<pre><code>## 
## Call:
##    felm(formula = DML2.RF$dtil ~ DML2.RF$ztil) 
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7411 -0.9755  0.0012  0.7718  3.2164 
## 
## Coefficients:
##              Estimate Robust s.e t value Pr(&gt;|t|)  
## (Intercept)   0.01578    0.15670   0.101   0.9201  
## DML2.RF$ztil -0.35243    0.18945  -1.860   0.0676 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.254 on 62 degrees of freedom
## Multiple R-squared(full model): 0.06352   Adjusted R-squared: 0.04842 
## Multiple R-squared(proj model): 0.06352   Adjusted R-squared: 0.04842 
## F-statistic(full model, *iid*):4.205 on 1 and 62 DF, p-value: 0.04453 
## F-statistic(proj model): 3.461 on 1 and 62 DF, p-value: 0.06759</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sm.OLS( DML2_RF[ <span class="st">&#39;dtil&#39;</span> ] , DML2_RF[ <span class="st">&#39;ztil&#39;</span> ] ).fit( cov_type <span class="op">=</span> <span class="st">&#39;HC1&#39;</span>, use_t <span class="op">=</span> <span class="va">True</span> ).summary())</span></code></pre></div>
<pre><code>##                                  OLS Regression Results                                
## =======================================================================================
## Dep. Variable:                      y   R-squared (uncentered):                   0.077
## Model:                            OLS   Adj. R-squared (uncentered):              0.063
## Method:                 Least Squares   F-statistic:                              4.178
## Date:                Wed, 24 Nov 2021   Prob (F-statistic):                      0.0451
## Time:                        16:38:39   Log-Likelihood:                         -106.72
## No. Observations:                  64   AIC:                                      215.4
## Df Residuals:                      63   BIC:                                      217.6
## Df Model:                           1                                                  
## Covariance Type:                  HC1                                                  
## ==============================================================================
##                  coef    std err          t      P&gt;|t|      [0.025      0.975]
## ------------------------------------------------------------------------------
## x1            -0.3971      0.194     -2.044      0.045      -0.785      -0.009
## ==============================================================================
## Omnibus:                        0.200   Durbin-Watson:                   1.601
## Prob(Omnibus):                  0.905   Jarque-Bera (JB):                0.202
## Skew:                           0.120   Prob(JB):                        0.904
## Kurtosis:                       2.866   Cond. No.                         1.00
## ==============================================================================
## 
## Notes:
## [1] R² is computed without centering (uncentered) since the model does not contain a constant.
## [2] Standard Errors are heteroscedasticity robust (HC1)</code></pre>
</div>
</div>
</div>
<div id="we-do-have-weak-instruments-because-t-stats-in-regression-tilde-d-sim-tilde-z-are-less-than-4-in-absolute-value" class="section level2" number="20.7">
<h2><span class="header-section-number">20.7</span> We do have weak instruments, because t-stats in regression <span class="math inline">\(\tilde D \sim \tilde Z\)</span> are less than 4 in absolute value</h2>
<p>So let’s carry out DML inference combined with Anderson-Rubin Idea</p>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DML-AR (DML with Anderson-Rubin) </span></span>
<span id="cb37-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-3" aria-hidden="true" tabindex="-1"></a>DML.AR.PLIV<span class="ot">&lt;-</span> <span class="cf">function</span>(rY, rD, rZ, grid, <span class="at">alpha=</span>.<span class="dv">05</span>){</span>
<span id="cb37-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-4" aria-hidden="true" tabindex="-1"></a>    n <span class="ot">=</span> <span class="fu">length</span>(rY)</span>
<span id="cb37-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-5" aria-hidden="true" tabindex="-1"></a>    Cstat <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">length</span>(grid))</span>
<span id="cb37-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(grid)) {</span>
<span id="cb37-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-7" aria-hidden="true" tabindex="-1"></a>    Cstat[i] <span class="ot">&lt;-</span>  n<span class="sc">*</span> (<span class="fu">mean</span>( (rY <span class="sc">-</span> grid[i]<span class="sc">*</span>rD)<span class="sc">*</span>rZ)  )<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="fu">var</span> ( (rY <span class="sc">-</span> grid[i]<span class="sc">*</span>rD) <span class="sc">*</span> rZ )</span>
<span id="cb37-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-8" aria-hidden="true" tabindex="-1"></a>    };</span>
<span id="cb37-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-9" aria-hidden="true" tabindex="-1"></a>    LB<span class="ot">&lt;-</span> <span class="fu">min</span>(grid[ Cstat <span class="sc">&lt;</span> <span class="fu">qchisq</span>(<span class="dv">1</span><span class="sc">-</span>alpha,<span class="dv">1</span>)]);</span>
<span id="cb37-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-10" aria-hidden="true" tabindex="-1"></a>    UB <span class="ot">&lt;-</span> <span class="fu">max</span>(grid[ Cstat <span class="sc">&lt;</span> <span class="fu">qchisq</span>(<span class="dv">1</span><span class="sc">-</span>alpha,<span class="dv">1</span>)]); </span>
<span id="cb37-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(<span class="fu">range</span>(grid),<span class="fu">range</span>(<span class="fu">c</span>( Cstat)) , <span class="at">type=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Effect of institutions&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Statistic&quot;</span>, <span class="at">main=</span><span class="st">&quot; &quot;</span>);  </span>
<span id="cb37-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(grid, Cstat,   <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> <span class="dv">1</span>);       </span>
<span id="cb37-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">h=</span><span class="fu">qchisq</span>(<span class="dv">1</span><span class="sc">-</span>alpha,<span class="dv">1</span>), <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="dv">4</span>);</span>
<span id="cb37-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">v=</span>LB, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="dv">2</span>);</span>
<span id="cb37-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>(<span class="at">v=</span>UB, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">col =</span> <span class="dv">2</span>);</span>
<span id="cb37-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">UB=</span>UB, <span class="at">LB=</span>LB))</span>
<span id="cb37-17"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb37-17" aria-hidden="true" tabindex="-1"></a>    }</span></code></pre></div>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># DML-AR (DML with Anderson-Rubin) </span></span>
<span id="cb38-3"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> DML_AR_PLIV( rY, rD, rZ, grid, alpha <span class="op">=</span> <span class="fl">0.05</span> ):</span>
<span id="cb38-4"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-4" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> rY.size</span>
<span id="cb38-5"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-5" aria-hidden="true" tabindex="-1"></a>    Cstat <span class="op">=</span> np.zeros( grid.size )</span>
<span id="cb38-6"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( <span class="dv">0</span> , grid.size ):</span>
<span id="cb38-8"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-8" aria-hidden="true" tabindex="-1"></a>        Cstat[ i ] <span class="op">=</span> n <span class="op">*</span> ( ( np.mean( ( rY <span class="op">-</span> grid[ i ] <span class="op">*</span> rD ) <span class="op">*</span> rZ )  ) <span class="op">**</span> <span class="dv">2</span> ) <span class="op">/</span> np.var( ( rY <span class="op">-</span> grid[ i ] <span class="op">*</span> rD ) <span class="op">*</span> rZ )</span>
<span id="cb38-9"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-10" aria-hidden="true" tabindex="-1"></a>    LB <span class="op">=</span> np.<span class="bu">min</span>( grid[  Cstat <span class="op">&lt;</span> chi2.ppf( <span class="dv">1</span> <span class="op">-</span> alpha , <span class="dv">1</span>) ] )</span>
<span id="cb38-11"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-11" aria-hidden="true" tabindex="-1"></a>    UB <span class="op">=</span> np.<span class="bu">max</span>( grid[  Cstat <span class="op">&lt;</span> chi2.ppf( <span class="dv">1</span> <span class="op">-</span> alpha , <span class="dv">1</span>) ] )</span>
<span id="cb38-12"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-13"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-13" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb38-14"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-15" aria-hidden="true" tabindex="-1"></a>    ax.plot(grid, Cstat, color<span class="op">=</span><span class="st">&#39;black&#39;</span>, label<span class="op">=</span><span class="st">&#39;Sine wave&#39;</span> )</span>
<span id="cb38-16"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-17"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-17" aria-hidden="true" tabindex="-1"></a>    ax.axhline( y <span class="op">=</span> chi2.ppf( <span class="dv">1</span> <span class="op">-</span> <span class="fl">0.05</span> , <span class="dv">1</span>) , linestyle <span class="op">=</span> <span class="st">&quot;--&quot;</span> )</span>
<span id="cb38-18"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-18" aria-hidden="true" tabindex="-1"></a>    ax.axvline( x <span class="op">=</span> LB , color <span class="op">=</span> <span class="st">&#39;red&#39;</span> , linestyle <span class="op">=</span> <span class="st">&quot;--&quot;</span> )</span>
<span id="cb38-19"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-19" aria-hidden="true" tabindex="-1"></a>    ax.axvline( x <span class="op">=</span> UB , color <span class="op">=</span> <span class="st">&#39;red&#39;</span> , linestyle <span class="op">=</span> <span class="st">&quot;--&quot;</span> )</span>
<span id="cb38-20"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-21"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-21" aria-hidden="true" tabindex="-1"></a>    ax.set_ylabel(<span class="st">&#39;Statistic&#39;</span>)</span>
<span id="cb38-22"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-22" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">&#39;Effect of institutions&#39;</span>)</span>
<span id="cb38-23"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-24"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-24" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb38-25"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-25" aria-hidden="true" tabindex="-1"></a>    final_result <span class="op">=</span> { <span class="st">&#39;UB&#39;</span> : UB , <span class="st">&#39;LB&#39;</span> : LB }</span>
<span id="cb38-26"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb38-27"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb38-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> final_result</span></code></pre></div>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb39-1" aria-hidden="true" tabindex="-1"></a>A <span class="ot">&lt;-</span> <span class="fu">DML.AR.PLIV</span>(<span class="at">rY =</span> DML2.lasso<span class="sc">$</span>ytil, <span class="at">rD=</span> DML2.lasso<span class="sc">$</span>dtil, <span class="at">rZ=</span> DML2.lasso<span class="sc">$</span>ztil,</span>
<span id="cb39-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb39-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">grid =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="at">by =</span>.<span class="dv">01</span>))</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(A)</span></code></pre></div>
<pre><code>## $UB
## [1] 1.74
## 
## $LB
## [1] 0.44</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb42-1" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> DML_AR_PLIV(rY <span class="op">=</span> DML2_lasso[<span class="st">&#39;ytil&#39;</span>], rD<span class="op">=</span> DML2_lasso[<span class="st">&#39;dtil&#39;</span>], rZ<span class="op">=</span> DML2_lasso[<span class="st">&#39;ztil&#39;</span>],</span>
<span id="cb42-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb42-2" aria-hidden="true" tabindex="-1"></a>           grid <span class="op">=</span> np.arange( <span class="op">-</span><span class="dv">2</span>, <span class="fl">2.001</span>, <span class="fl">0.01</span> ) )</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-2-1.png" width="1152" /></p>
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span></code></pre></div>
<pre><code>## {&#39;UB&#39;: 2.0000000000000036, &#39;LB&#39;: -2.0}</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(A)</span></code></pre></div>
<pre><code>## $UB
## [1] 1.74
## 
## $LB
## [1] 0.44</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(A)</span></code></pre></div>
<pre><code>## {&#39;UB&#39;: 2.0000000000000036, &#39;LB&#39;: -2.0}</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb49-1" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">DML.AR.PLIV</span>(<span class="at">rY =</span> DML2.RF<span class="sc">$</span>ytil, <span class="at">rD=</span> DML2.RF<span class="sc">$</span>dtil, <span class="at">rZ=</span> DML2.RF<span class="sc">$</span>ztil,</span>
<span id="cb49-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb49-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">grid =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="at">by =</span>.<span class="dv">01</span>))</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb50-1" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> DML_AR_PLIV(rY <span class="op">=</span> DML2_RF[<span class="st">&#39;ytil&#39;</span>], rD<span class="op">=</span> DML2_RF[<span class="st">&#39;dtil&#39;</span>], rZ<span class="op">=</span> DML2_RF[<span class="st">&#39;ztil&#39;</span>],</span>
<span id="cb50-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb50-2" aria-hidden="true" tabindex="-1"></a>           grid <span class="op">=</span> np.arange( <span class="op">-</span><span class="dv">2</span>, <span class="fl">2.001</span>, <span class="fl">0.01</span> ) )</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-2-1.png" width="1152" /></p>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(B)</span></code></pre></div>
<pre><code>## $UB
## [1] 2
## 
## $LB
## [1] 0.36</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb53-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-2"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(B)</span></code></pre></div>
<pre><code>## {&#39;UB&#39;: 2.0000000000000036, &#39;LB&#39;: 0.3400000000000021}</code></pre>
</div>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/alexanderquispe/ml_book/edit/master/30-DML-Partially-Linear-IV.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/alexanderquispe/ml_book/blob/master/30-DML-Partially-Linear-IV.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
