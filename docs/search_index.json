[["machine-learning-for-wage-prediction.html", "Chapter 8 Machine Learning for wage prediction 8.1 Data 8.2 Analysis 8.3 OLS 8.4 Lasso, Ridge and Elastic Net 8.5 Non-linear models 8.6 Random Forest and Boosted Trees 8.7 Results 8.8 Ensemble learning", " Chapter 8 Machine Learning for wage prediction We illustrate how to predict an outcome variable Y in a high-dimensional setting, where the number of covariates \\(p\\) is large in relation to the sample size \\(n\\). So far we have used linear prediction rules, e.g. Lasso regression, for estimation. Now, we also consider nonlinear prediction rules including tree-based methods. 8.1 Data Again, we consider data from the U.S. March Supplement of the Current Population Survey (CPS) in 2015. The preproccessed sample consists of \\(5150\\) never-married individuals. .col2 { columns: 2 200px; /* number of columns and width in pixels*/ -webkit-columns: 2 200px; /* chrome, safari */ -moz-columns: 2 200px; /* firefox */ } .col3 { columns: 3 100px; -webkit-columns: 3 100px; -moz-columns: 3 100px; } load(&quot;./data/wage2015_subsample_inference.Rdata&quot;) dim(data) ## [1] 5150 20   # Importing relevant libraries import pandas as pd import numpy as np import pyreadr import math import matplotlib.pyplot as plt import random rdata_read = pyreadr.read_r(&quot;./data/wage2015_subsample_inference.Rdata&quot;) # Extracting the data frame from rdata_read data = rdata_read[&quot;data&quot;] data.shape ## (5150, 20) The outcomes \\(Y_i\\)s are hourly (log) wages of never-married workers living in the U.S. The raw regressors \\(Z_i\\)s consist of a variety of characteristics, including experience, education and industry and occupation indicators. Z &lt;- subset(data, select=-c(lwage,wage)) # regressors colnames(Z) ## [1] &quot;sex&quot; &quot;shs&quot; &quot;hsg&quot; &quot;scl&quot; &quot;clg&quot; &quot;ad&quot; &quot;mw&quot; &quot;so&quot; &quot;we&quot; &quot;ne&quot; ## [11] &quot;exp1&quot; &quot;exp2&quot; &quot;exp3&quot; &quot;exp4&quot; &quot;occ&quot; &quot;occ2&quot; &quot;ind&quot; &quot;ind2&quot;   Z = data.loc[:, &#39;sex&#39;:&#39;ind2&#39;] Z.columns ## Index([&#39;sex&#39;, &#39;shs&#39;, &#39;hsg&#39;, &#39;scl&#39;, &#39;clg&#39;, &#39;ad&#39;, &#39;mw&#39;, &#39;so&#39;, &#39;we&#39;, &#39;ne&#39;, &#39;exp1&#39;, ## &#39;exp2&#39;, &#39;exp3&#39;, &#39;exp4&#39;, &#39;occ&#39;, &#39;occ2&#39;, &#39;ind&#39;, &#39;ind2&#39;], ## dtype=&#39;object&#39;) The following figure shows the weekly wage distribution from the US survey data. hist(data$wage, xlab= &quot;hourly wage&quot;, main = &quot;Empirical wage distribution from the US survey data&quot;, breaks = 35)   plt.hist(data.wage , bins = np.arange(0, 550, 20) ) ## (array([2.783e+03, 1.858e+03, 3.520e+02, 9.200e+01, 3.600e+01, 1.100e+01, ## 5.000e+00, 3.000e+00, 0.000e+00, 2.000e+00, 1.000e+00, 0.000e+00, ## 1.000e+00, 1.000e+00, 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, ## 0.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, ## 1.000e+00, 0.000e+00, 2.000e+00]), array([ 0, 20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240, ## 260, 280, 300, 320, 340, 360, 380, 400, 420, 440, 460, 480, 500, ## 520, 540]), &lt;BarContainer object of 27 artists&gt;) plt.xlabel(&#39;hourly wage&#39;) plt.ylabel(&#39;Frequency&#39;) plt.title( &#39;Empirical wage distribution from the US survey data&#39; ) plt.ylim((0, 3000)) ## (0.0, 3000.0) plt.show() Wages show a high degree of skewness. Hence, wages are transformed in almost all studies by the logarithm. 8.2 Analysis Due to the skewness of the data, we are considering log wages which leads to the following regression model \\[log(wage) = g(Z) + \\epsilon.\\] We will estimate the two sets of prediction rules: Linear and Nonlinear Models. In linear models, we estimate the prediction rule of the form \\[\\hat g(Z) = \\hat \\beta&#39;X.\\] Again, we generate \\(X\\) in two ways: Basic Model: \\(X\\) consists of a set of raw regressors (e.g. gender, experience, education indicators, regional indicators). Flexible Model: \\(X\\) consists of all raw regressors from the basic model plus occupation and industry indicators, transformations (e.g., \\({exp}^2\\) and \\({exp}^3\\)) and additional two-way interactions. To evaluate the out-of-sample performance, we split the data first. set.seed(1234) training &lt;- sample(nrow(data), nrow(data)*(3/4), replace = FALSE) data_train &lt;- data[training,] data_test &lt;- data[-training,] # Checking dimensions dim(data_test) ## [1] 1288 20 dim(data_train) ## [1] 3862 20   # Setting parameters to split the data nrow = data.shape[0] length = int(nrow*(3/4)) data = data.reset_index().drop( &#39;rownames&#39;, axis = 1) # Splitting the data from numpy.random import default_rng random.seed(30) rng = default_rng() training = rng.choice(nrow, size = length, replace=False) training_bool = data.index.isin( training ) data_train = data.iloc[training,:] data_test = data[~training_bool] # Checking dimensions data_test.shape ## (1288, 20) data_train.shape ## (3862, 20) We construct the two different model matrices \\(X_{basic}\\) and \\(X_{flex}\\) for both the training and the test sample: X_basic &lt;- &quot;sex + exp1 + exp2+ shs + hsg+ scl + clg + mw + so + we + occ2+ ind2&quot; X_flex &lt;- &quot;sex + exp1 + exp2 + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)&quot; # Formulas formula_basic &lt;- as.formula(paste(&quot;lwage&quot;, &quot;~&quot;, X_basic)) formula_flex &lt;- as.formula(paste(&quot;lwage&quot;, &quot;~&quot;, X_flex)) # Models model_X_basic_train &lt;- model.matrix(formula_basic,data_train) model_X_basic_test &lt;- model.matrix(formula_basic,data_test) p_basic &lt;- dim(model_X_basic_train)[2] # regressors model_X_flex_train &lt;- model.matrix(formula_flex,data_train) model_X_flex_test &lt;- model.matrix(formula_flex,data_test) p_flex &lt;- dim(model_X_flex_train)[2] # regressors Y_train &lt;- data_train$lwage Y_test &lt;- data_test$lwage # Dimensions dim(model_X_basic_train) ## [1] 3862 52 p_basic ## [1] 52 p_flex ## [1] 246   # Importing relevant libraries import statsmodels.api as sm import statsmodels.formula.api as smf import patsy # Formulas formula_basic = &quot;lwage ~ sex + exp1 + exp2+ shs + hsg+ scl + clg + mw + so + we + occ2+ ind2&quot; formula_flex = &quot;lwage ~ sex + exp1 + exp2 + shs+hsg+scl+clg+occ2+ind2+mw+so+we + (exp1+exp2+exp3+exp4)*(shs+hsg+scl+clg+occ2+ind2+mw+so+we)&quot; # Models y_basic_train, model_X_basic_train = patsy.dmatrices(formula_basic, data_train, return_type=&#39;dataframe&#39;) y_basic_test , model_X_basic_test = patsy.dmatrices(formula_basic, data_test, return_type=&#39;dataframe&#39;) p_basic = model_X_basic_train.shape[ 1 ] # regressors y_flex_train, model_X_flex_train = patsy.dmatrices(formula_flex, data_train, return_type=&#39;dataframe&#39;) y_flex_test , model_X_flex_test = patsy.dmatrices(formula_flex, data_test, return_type=&#39;dataframe&#39;) p_flex = model_X_flex_train.shape[ 1 ] # regressors Y_train = data_train[&#39;lwage&#39;] Y_test = data_test[&#39;lwage&#39;] # Dimensions model_X_basic_train.shape ## (3862, 52) print(p_basic) ## 52 print(p_flex) ## 246 As known from our first lab, the basic model consists of \\(10\\) regressors and the flexible model of \\(246\\) regressors. Let us fit our models to the training sample using the two different model specifications. We are starting by running a simple ols regression. 8.3 OLS We fit the basic model to our training data by running an ols regression and compute the mean squared error on the test sample. # OLS (basic model) fit.lm.basic &lt;- lm(formula_basic, data_train) # Compute out-of-sample performance yhat.lm.basic &lt;- predict(fit.lm.basic, newdata=data_test) cat(&quot;The mean squared error (MSE) using the basic model is equal to&quot; , mean((Y_test-yhat.lm.basic)^2)) # MSE OLS (basic model) ## The mean squared error (MSE) using the basic model is equal to 0.2293541   # OLS (basic model) lm_basic = sm.OLS( Y_train, model_X_basic_train ) fit_lm_basic = lm_basic.fit() # Compute out-of-sample performance yhat_lm_basic = fit_lm_basic.predict( model_X_basic_test ) print( f&quot;The mean squared error (MSE) using the basic model is equal to , {np.mean((Y_test-yhat_lm_basic)**2)} &quot;) # MSE OLS (basic model) ## The mean squared error (MSE) using the basic model is equal to , 0.22818615112815013 To determine the out-of-sample \\(MSE\\) and the standard error in one step, we can use the function lm: MSE.lm.basic &lt;- summary(lm((Y_test-yhat.lm.basic)^2~1))$coef[1:2] MSE.lm.basic ## [1] 0.22935406 0.01564666   # OLS (basic model) resid_basic = (Y_test-yhat_lm_basic)**2 MSE_lm_basic = sm.OLS( resid_basic , np.ones( resid_basic.shape[0] ) ).fit().summary2().tables[1].iloc[0, 0:2] MSE_lm_basic ## Coef. 0.228186 ## Std.Err. 0.015958 ## Name: const, dtype: float64 We also compute the out-of-sample \\(R^2\\): R2.lm.basic &lt;- 1 - MSE.lm.basic[1]/var(Y_test) cat(&quot;The R^2 using the basic model is equal to&quot;,R2.lm.basic) # MSE OLS (basic model) ## The R^2 using the basic model is equal to 0.2819899   R2_lm_basic = 1 - ( MSE_lm_basic[0]/Y_test.var() ) print( f&quot;The R^2 using the basic model is equal to, {R2_lm_basic}&quot; ) # MSE OLS (basic model) ## The R^2 using the basic model is equal to, 0.28398713111832197 We repeat the same procedure for the flexible model. # OLS (flexible model) fit.lm.flex &lt;- lm(formula_flex, data_train) # Compute the out-of-sample performance options(warn=-1) yhat.lm.flex &lt;- predict(fit.lm.flex, newdata=data_test) MSE.lm.flex &lt;- summary(lm((Y_test-yhat.lm.flex)^2~1))$coef[1:2] # MSE and R squared R2.lm.flex &lt;- 1 - MSE.lm.flex[1]/var(Y_test) cat(&quot;The R^2 using the flexible model is equal to&quot;,R2.lm.flex) # MSE OLS (flexible model) ## The R^2 using the flexible model is equal to 0.2383204   # OLS (flex model) lm_flex = sm.OLS( Y_train, model_X_flex_train ) fit_lm_flex = lm_flex.fit() # Compute the out-of-sample performance yhat_lm_flex = fit_lm_flex.predict( model_X_flex_test ) resid_flex = (Y_test-yhat_lm_flex)**2 # MSE and R squared MSE_lm_flex = sm.OLS( resid_flex , np.ones( resid_flex.shape[0] ) ).fit().summary2().tables[1].iloc[0, 0:2] MSE_lm_flex ## Coef. 0.247651 ## Std.Err. 0.016709 ## Name: const, dtype: float64 R2_lm_flex = 1 - ( MSE_lm_flex[0]/Y_test.var() ) print( f&quot;The R^2 using the flex model is equal to, {R2_lm_flex}&quot; ) # MSE OLS (flex model) ## The R^2 using the flex model is equal to, 0.22290844960856848 We observe that ols regression works better for the basic model with smaller \\(p/n\\) ratio. We are proceeding by running lasso regressions and its versions. 8.4 Lasso, Ridge and Elastic Net Considering the basic model, we run a lasso/post-lasso regression first and then we compute the measures for the out-of-sample performance. Note that applying the package hdm and the function rlasso we rely on a theoretical based choice of the penalty level \\(\\lambda\\) in the lasso regression. # lasso and versions library(hdm) fit.rlasso &lt;- rlasso(formula_basic, data_train, post=FALSE) fit.rlasso.post &lt;- rlasso(formula_basic, data_train, post=TRUE)   import warnings warnings.filterwarnings(&quot;ignore&quot;) import hdmpy fit_rlasso = hdmpy.rlasso( model_X_basic_train.to_numpy() , Y_train.to_numpy().reshape( Y_train.size , 1 ) , post = False ) fit_rlasso_post = hdmpy.rlasso( model_X_basic_train.to_numpy() , Y_train.to_numpy().reshape( Y_train.size , 1 ) , post = True ) Estimating the predictions from rlasso models We have to know that the residuals output come from this formula: x1 = x - np.ones( (x.shape[1] , 1) ) @ x.mean( axis = 0 ) beta = model.est[beta].loc[ fit_rlasso.est[index].iloc[:, 0].to_list(), ].to_numpy() y1 = y - y.mean() yhat = x1 @ beta + y.mean() So we have to apply those transformations to original test data # lasso and versions library(hdm) yhat.rlasso &lt;- predict(fit.rlasso, newdata=data_test) yhat.rlasso.post &lt;- predict(fit.rlasso.post, newdata=data_test) MSE.lasso &lt;- summary(lm((Y_test-yhat.rlasso)^2~1))$coef[1:2] MSE.lasso.post &lt;- summary(lm((Y_test-yhat.rlasso.post)^2~1))$coef[1:2] R2.lasso &lt;- 1-MSE.lasso[1]/var(Y_test) R2.lasso.post &lt;- 1-MSE.lasso.post[1]/var(Y_test) cat(&quot;The R^2 using the basic model is equal to&quot;,R2.lasso,&quot;for lasso and&quot;,R2.lasso.post,&quot;for post-lasso&quot;) # R^2 lasso/post-lasso (basic model) ## The R^2 using the basic model is equal to 0.2674345 for lasso and 0.2706874 for post-lasso   # Getting mean of each variable meanx = model_X_basic_test.mean( axis = 0 ).values.\\ reshape( model_X_basic_test.shape[ 1 ] , 1 ) # Reducing the mean new_x1 = model_X_basic_test.to_numpy() - \\ (np.ones( ( model_X_basic_test.shape[ 0 ] , 1 ) ) @ meanx.T) # Getting the significant variables x1_est_rlasso = new_x1[ :, fit_rlasso.est[&#39;index&#39;].iloc[:, 0].to_list()] # Getting the coef. from significant variables beta_rlasso = fit_rlasso.est[&#39;beta&#39;].loc[ fit_rlasso.est[&#39;index&#39;].\\ iloc[:, 0].to_list(), ].to_numpy() # yhat yhat_rlasso = (x1_est_rlasso @ beta_rlasso) + np.mean( Y_test.to_numpy() ) residuals_rlasso = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1) - yhat_rlasso # Getting mean of each variable meanx = model_X_basic_test.mean( axis = 0 ).values.\\ reshape( model_X_basic_test.shape[ 1 ] , 1 ) # Reducing the mean new_x1 = model_X_basic_test.to_numpy() - \\ (np.ones( ( model_X_basic_test.shape[ 0 ] , 1 ) ) @ meanx.T) # Getting the significant variables x1_est_rlasso_post = new_x1[ :, fit_rlasso_post.est[&#39;index&#39;].iloc[:, 0].to_list()] # Getting the coef. from significant variables beta_rlasso_post = fit_rlasso_post.est[&#39;beta&#39;].loc[ fit_rlasso_post.est[&#39;index&#39;].\\ iloc[:, 0].to_list(), ].to_numpy() # yhat yhat_rlasso_post = (x1_est_rlasso_post @ beta_rlasso_post) + np.mean( Y_test.to_numpy() ) residuals_rlasso_post = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1) - yhat_rlasso_post MSE_lasso = sm.OLS( ( residuals_rlasso )**2 , np.ones( yhat_rlasso.size ) ).fit().summary2().tables[1].round(3) MSE_lasso_post = sm.OLS( ( residuals_rlasso_post )**2 , np.ones( yhat_rlasso_post.size ) ).fit().summary2().tables[1].round(3) R2_lasso = 1 - MSE_lasso.iloc[0, 0]/ np.var( Y_test ) R2_lasso_post = 1 - MSE_lasso_post.iloc[0, 0]/ np.var( Y_test ) print( f&quot;The R^2 using the basic model is equal to {R2_lasso},for lasso and {R2_lasso_post} for post-lasso&quot;) # R^2 lasso/post-lasso (basic model) ## The R^2 using the basic model is equal to 0.243191670035374,for lasso and 0.243191670035374 for post-lasso Now, we repeat the same procedure for the flexible model. # lasso and versions fit.rlasso.flex &lt;- rlasso(formula_flex, data_train, post=FALSE) fit.rlasso.post.flex &lt;- rlasso(formula_flex, data_train, post=TRUE) yhat.rlasso.flex &lt;- predict(fit.rlasso.flex, newdata=data_test) yhat.rlasso.post.flex &lt;- predict(fit.rlasso.post.flex, newdata=data_test) MSE.lasso.flex &lt;- summary(lm((Y_test-yhat.rlasso.flex)^2~1))$coef[1:2] MSE.lasso.post.flex &lt;- summary(lm((Y_test-yhat.rlasso.post.flex)^2~1))$coef[1:2] R2.lasso.flex &lt;- 1-MSE.lasso.flex[1]/var(Y_test) R2.lasso.post.flex &lt;- 1-MSE.lasso.post.flex[1]/var(Y_test) cat(&quot;The R^2 using the flexible model is equal to&quot;,R2.lasso.flex,&quot;for lasso and&quot;,R2.lasso.post.flex,&quot;for post-lasso&quot;) # R^2 lasso/post-lasso (flexible model) ## The R^2 using the flexible model is equal to 0.2653058 for lasso and 0.2614714 for post-lasso   fit_rlasso_flex = hdmpy.rlasso( model_X_flex_train.to_numpy() , Y_train.to_numpy().reshape( Y_train.size , 1 ) , post = False ) fit_rlasso_post_flex = hdmpy.rlasso( model_X_flex_train.to_numpy() , Y_train.to_numpy().reshape( Y_train.size , 1 ) , post = True ) # Getting mean of each variable meanx = model_X_flex_test.mean( axis = 0 ).values.\\ reshape( model_X_flex_test.shape[ 1 ] , 1 ) # Reducing the mean new_x1 = model_X_flex_test.to_numpy() - \\ (np.ones( ( model_X_flex_test.shape[ 0 ] , 1 ) ) @ meanx.T) # Getting the significant variables x1_est_rlasso_flex = new_x1[ :, fit_rlasso_flex.est[&#39;index&#39;].iloc[:, 0].to_list()] # Getting the coef. from significant variables beta_rlasso_flex = fit_rlasso_flex.est[&#39;beta&#39;].loc[ fit_rlasso_flex.est[&#39;index&#39;].\\ iloc[:, 0].to_list(), ].to_numpy() # yhat yhat_rlasso_flex = (x1_est_rlasso_flex @ beta_rlasso_flex) + np.mean( Y_test.to_numpy() ) residuals_rlasso_flex = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1) - yhat_rlasso_flex # Getting mean of each variable meanx = model_X_flex_test.mean( axis = 0 ).values.\\ reshape( model_X_flex_test.shape[ 1 ] , 1 ) # Reducing the mean new_x1 = model_X_flex_test.to_numpy() - \\ (np.ones( ( model_X_flex_test.shape[ 0 ] , 1 ) ) @ meanx.T) # Getting the significant variables x1_est_rlasso_post_flex = new_x1[ :, fit_rlasso_post_flex.est[&#39;index&#39;].iloc[:, 0].to_list()] # Getting the coef. from significant variables beta_rlasso_post_flex = fit_rlasso_post_flex.est[&#39;beta&#39;].loc[ fit_rlasso_post_flex.est[&#39;index&#39;].\\ iloc[:, 0].to_list(), ].to_numpy() # yhat yhat_rlasso_post_flex = (x1_est_rlasso_post_flex @ beta_rlasso_post_flex) + np.mean( Y_test.to_numpy() ) residuals_rlasso_post_flex = Y_test.to_numpy().reshape( Y_test.to_numpy().size, 1) - yhat_rlasso_post_flex MSE_lasso_flex = sm.OLS( ( residuals_rlasso_flex )**2 , np.ones( yhat_rlasso_flex.size ) ).fit().summary2().tables[1].round(3) MSE_lasso_post_flex = sm.OLS( ( residuals_rlasso_post_flex )**2 , np.ones( yhat_rlasso_post_flex.size ) ).fit().summary2().tables[1].round(3) R2_lasso_flex = 1 - MSE_lasso.iloc[0, 0]/ np.var( Y_test ) R2_lasso_post_flex = 1 - MSE_lasso_post_flex.iloc[0, 0]/ np.var( Y_test ) print( f&quot;The R^2 using the basic model is equal to {R2_lasso_flex},for lasso and {R2_lasso_post_flex} for post-lasso&quot;) # R^2 lasso/post-lasso (basic model) ## The R^2 using the basic model is equal to 0.243191670035374,for lasso and 0.23063053592807725 for post-lasso It is worth to notice that lasso regression works better for the more complex model. In contrast to a theoretical based choice of the tuning parameter \\(\\lambda\\) in the lasso regression, we can also use cross-validation to determine the penalty level by applying the package glmnet and the function cv.glmnet. In this context, we also run a ridge and a elastic net regression by adjusting the parameter alpha. library(glmnet) ## Loading required package: Matrix ## Loaded glmnet 4.1-2 fit.lasso.cv &lt;- cv.glmnet(model_X_basic_train, Y_train, family=&quot;gaussian&quot;, alpha=1) fit.ridge &lt;- cv.glmnet(model_X_basic_train, Y_train, family=&quot;gaussian&quot;, alpha=0) fit.elnet &lt;- cv.glmnet(model_X_basic_train, Y_train, family=&quot;gaussian&quot;, alpha=.5) yhat.lasso.cv &lt;- predict(fit.lasso.cv, newx = model_X_basic_test) yhat.ridge &lt;- predict(fit.ridge, newx = model_X_basic_test) yhat.elnet &lt;- predict(fit.elnet, newx = model_X_basic_test) MSE.lasso.cv &lt;- summary(lm((Y_test-yhat.lasso.cv)^2~1))$coef[1:2] MSE.ridge &lt;- summary(lm((Y_test-yhat.ridge)^2~1))$coef[1:2] MSE.elnet &lt;- summary(lm((Y_test-yhat.elnet)^2~1))$coef[1:2] R2.lasso.cv &lt;- 1-MSE.lasso.cv[1]/var(Y_test) R2.ridge &lt;- 1-MSE.ridge[1]/var(Y_test) R2.elnet &lt;- 1-MSE.elnet[1]/var(Y_test) # R^2 using cross-validation (basic model) cat(&quot;R^2 using cross-validation for lasso, ridge and elastic net in the basic model:&quot;,R2.lasso.cv,R2.ridge,R2.elnet) ## R^2 using cross-validation for lasso, ridge and elastic net in the basic model: 0.2824847 0.2669501 0.28039   from sklearn.linear_model import LassoCV from sklearn.preprocessing import StandardScaler from sklearn.linear_model import RidgeCV, ElasticNetCV import statsmodels.api as sm # Reshaping Y variable Y_vec = Y_train.to_numpy().reshape( Y_train.to_numpy().size, 1) # Scalar distribution scaler = StandardScaler() scaler.fit( Y_vec ) ## StandardScaler() std_Y = scaler.transform( Y_vec ) # Regressions fit_lasso_cv_basic = LassoCV(cv = 10 , random_state = 0 , normalize = True ).fit( model_X_basic_train, std_Y ) fit_ridge_basic = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001 ).fit( model_X_basic_train , std_Y ) fit_elnet_basic = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ).fit( model_X_basic_train , std_Y ) # Predictions yhat_lasso_cv_basic = scaler.inverse_transform( fit_lasso_cv_basic.predict( model_X_basic_test ) ) yhat_ridge_basic = scaler.inverse_transform( fit_ridge_basic.predict( model_X_basic_test ) ) yhat_elnet_basic = scaler.inverse_transform( fit_elnet_basic.predict( model_X_basic_test ) ) MSE_lasso_cv_basic = sm.OLS( ((Y_test - yhat_lasso_cv_basic)**2 ) , np.ones( yhat_lasso_cv_basic.shape ) ).fit().summary2().tables[1].round(3) MSE_ridge_basic = sm.OLS( ((Y_test - yhat_ridge_basic)**2 ) , np.ones( yhat_ridge_basic.size ) ).fit().summary2().tables[1].round(3) MSE_elnet_basic = sm.OLS( ((Y_test - yhat_elnet_basic)**2 ) , np.ones( yhat_elnet_basic.size ) ).fit().summary2().tables[1].round(3) # our coefficient of MSE_elnet are far from r output R2_lasso_cv_basic = 1- MSE_ridge_basic.iloc[0,0] / np.var( Y_test ) R2_ridge_basic = 1- MSE_lasso_cv_basic.iloc[0,0] / np.var( Y_test ) R2_elnet_basic = 1- MSE_elnet_basic.iloc[0,0] / np.var( Y_test ) print( f&quot;R^2 using cross-validation for lasso, ridge and elastic net in the basic model: {R2_lasso_cv_basic},{R2_ridge_basic},{R2_elnet_basic}&quot;) ## R^2 using cross-validation for lasso, ridge and elastic net in the basic model: 0.004530121996736747,0.28087507235726406,0.2777347888304399 Note that the following calculations for the flexible model require significant computation time. fit.lasso.cv.flex &lt;- cv.glmnet(model_X_flex_train, Y_train, family=&quot;gaussian&quot;, alpha=1) fit.ridge.flex &lt;- cv.glmnet(model_X_flex_train, Y_train, family=&quot;gaussian&quot;, alpha=0) fit.elnet.flex &lt;- cv.glmnet(model_X_flex_train, Y_train, family=&quot;gaussian&quot;, alpha=.5) yhat.lasso.cv.flex &lt;- predict(fit.lasso.cv.flex , newx = model_X_flex_test) yhat.ridge.flex &lt;- predict(fit.ridge.flex , newx = model_X_flex_test) yhat.elnet.flex &lt;- predict(fit.elnet.flex , newx = model_X_flex_test) MSE.lasso.cv.flex &lt;- summary(lm((Y_test-yhat.lasso.cv.flex )^2~1))$coef[1:2] MSE.ridge.flex &lt;- summary(lm((Y_test-yhat.ridge.flex )^2~1))$coef[1:2] MSE.elnet.flex &lt;- summary(lm((Y_test-yhat.elnet.flex )^2~1))$coef[1:2] R2.lasso.cv.flex &lt;- 1-MSE.lasso.cv.flex [1]/var(Y_test) R2.ridge.flex &lt;- 1-MSE.ridge.flex [1]/var(Y_test) R2.elnet.flex &lt;- 1-MSE.elnet.flex [1]/var(Y_test) # R^2 using cross-validation (flexible model) cat(&quot;R^2 using cross-validation for lasso, ridge and elastic net in the flexible model:&quot;,R2.lasso.cv.flex,R2.ridge.flex,R2.elnet.flex) ## R^2 using cross-validation for lasso, ridge and elastic net in the flexible model: 0.2751157 0.2710676 0.2761405   # Reshaping Y variable Y_vec = Y_train.to_numpy().reshape( Y_train.to_numpy().size, 1) # Scalar distribution scaler = StandardScaler() scaler.fit( Y_vec ) ## StandardScaler() std_Y = scaler.transform( Y_vec ) # Regressions fit_lasso_cv_flex = LassoCV(cv = 10 , random_state = 0 , normalize = True ).fit( model_X_flex_train, std_Y ) fit_ridge_flex = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.0001 ).fit( model_X_flex_train , std_Y ) fit_elnet_flex = ElasticNetCV( cv = 10 , normalize = True , random_state = 0 , l1_ratio = 0.5, max_iter = 100000 ).fit( model_X_flex_train , std_Y ) # Predictions yhat_lasso_cv_flex = scaler.inverse_transform( fit_lasso_cv_flex.predict( model_X_flex_test ) ) yhat_ridge_flex = scaler.inverse_transform( fit_ridge_flex.predict( model_X_flex_test ) ) yhat_elnet_flex = scaler.inverse_transform( fit_elnet_flex.predict( model_X_flex_test ) ) MSE_lasso_cv_flex = sm.OLS( ((Y_test - yhat_lasso_cv_flex)**2 ) , np.ones( yhat_lasso_cv_flex.shape ) ).fit().summary2().tables[1].round(3) MSE_ridge_flex = sm.OLS( ((Y_test - yhat_ridge_flex)**2 ) , np.ones( yhat_ridge_flex.size ) ).fit().summary2().tables[1].round(3) MSE_elnet_flex = sm.OLS( ((Y_test - yhat_elnet_flex)**2 ) , np.ones( yhat_elnet_flex.size ) ).fit().summary2().tables[1].round(3) # our coefficient of MSE_elnet are far from r output R2_lasso_cv_flex = 1- MSE_ridge_flex.iloc[0,0] / np.var( Y_test ) R2_ridge_flex = 1- MSE_lasso_cv_flex.iloc[0,0] / np.var( Y_test ) R2_elnet_flex = 1- MSE_elnet_flex.iloc[0,0] / np.var( Y_test ) print( f&quot;R^2 using cross-validation for lasso, ridge and elastic net in the basic model: {R2_lasso_cv_flex},{R2_ridge_flex},{R2_elnet_flex}&quot;) ## R^2 using cross-validation for lasso, ridge and elastic net in the basic model: 0.01081068905038507,0.2777347888304399,0.26517365472314314 The performance of the lasso regression with cross-validated penalty is quite similar to the performance of lasso using a theoretical based choice of the tuning parameter. 8.5 Non-linear models Besides linear regression models, we consider nonlinear regression models to build a predictive model. We are applying regression trees, random forests, boosted trees and neural nets to estimate the regression function \\(g(X)\\). First, we load the relevant libraries library(randomForest) ## randomForest 4.6-14 ## Type rfNews() to see new features/changes/bug fixes. library(rpart) library(nnet) library(gbm) ## Loaded gbm 2.1.8 library(rpart.plot) library(reticulate) import(&quot;tensorflow&quot;) ## Module(tensorflow) import(&quot;keras&quot;) ## Module(keras) library(keras)   # in process and we illustrate the application of regression trees. 8.5.1 Regression Trees We fit a regression tree to the training data using the basic model. The variable cp controls the complexity of the regression tree, i.e. how deep we build the tree. # tree fit.trees &lt;- rpart(formula_basic, data_train,cp = 0.001) prp(fit.trees,leaf.round=1, space=2, yspace=2,split.space=2,shadow.col = &quot;gray&quot;,trace = 1) # plotting the tree ## cex 0.15 xlim c(0, 1) ylim c(0, 1)   # in process An important method to improve predictive performance is called Pruning the Tree. This means the process of cutting down the branches of a tree. We apply pruning to the complex tree above to reduce the depth. Initially, we determine the optimal complexity of the regression tree. bestcp&lt;- fit.trees$cptable[which.min(fit.trees$cptable[,&quot;xerror&quot;]),&quot;CP&quot;] bestcp ## [1] 0.002556354   # in process Now, we can prune the tree and visualize the prediction rule. fit.prunedtree &lt;- prune(fit.trees,cp=bestcp) prp(fit.prunedtree,leaf.round=1, space=3, yspace=3, split.space=7, shadow.col = &quot;gray&quot;,trace = 1,yesno=1) ## cex 0.263 xlim c(0, 1) ylim c(0, 1)   # in process E.g., in the pruned tree the predicted hourly log wage for high-school graduates with more than \\(9.5\\) years of experience is \\(2.8\\), and otherwise is \\(2.6\\). Finally, we calculate the mean-squared error and the \\(R^2\\) on the test sample to evaluate the out-of-sample performance of the pruned tree. bestcp&lt;- fit.trees$cptable[which.min(fit.trees$cptable[,&quot;xerror&quot;]),&quot;CP&quot;] bestcp ## [1] 0.002556354   # in process Now, we can prune the tree and visualize the prediction rule. yhat.pt &lt;- predict(fit.prunedtree,newdata=data_test) MSE.pt &lt;- summary(lm((Y_test-yhat.pt)^2~1))$coef[1:2] R2.pt &lt;- 1-MSE.pt[1]/var(Y_test) # R^2 of the pruned tree cat(&quot;R^2 of the pruned tree:&quot;,R2.pt) ## R^2 of the pruned tree: 0.2238947   # in process 8.6 Random Forest and Boosted Trees In the next step, we apply the more advanced tree-based methods random forest and boosted trees. bestcp&lt;- fit.trees$cptable[which.min(fit.trees$cptable[,&quot;xerror&quot;]),&quot;CP&quot;] bestcp ## [1] 0.002556354   # in process Now, we can prune the tree and visualize the prediction rule. ## Applying the methods # random forest fit.rf &lt;- randomForest(formula_basic, ntree=2000, nodesize=5, data=data_train) # for tuning: adjust input &quot;mtry&quot; to change the number of variables randomly sampled as candidates at each split # boosting fit.boost &lt;- gbm(formula_basic, data=data_train, distribution= &quot;gaussian&quot;, bag.fraction = .5, interaction.depth=2, n.trees=1000, shrinkage=.01) best.boost &lt;- gbm.perf(fit.boost, plot.it = FALSE) # cross-validation to determine when to stop ## OOB generally underestimates the optimal number of iterations although predictive performance is reasonably competitive. Using cv_folds&gt;1 when calling gbm usually results in improved predictive performance. ## Evaluating the methods yhat.rf &lt;- predict(fit.rf, newdata=data_test) # prediction yhat.boost &lt;- predict(fit.boost, newdata=data_test, n.trees=best.boost) MSE.rf &lt;- summary(lm((Y_test-yhat.rf)^2~1))$coef[1:2] MSE.boost &lt;- summary(lm((Y_test-yhat.boost)^2~1))$coef[1:2] R2.rf &lt;- 1-MSE.rf[1]/var(Y_test) R2.boost &lt;- 1-MSE.boost[1]/var(Y_test) # printing R^2 cat(&quot;R^2 of the random forest and boosted trees:&quot;,R2.rf,R2.boost) ## R^2 of the random forest and boosted trees: 0.2695651 0.2786383   # in process To conclude, let us have a look at our results. 8.7 Results library(xtable) table&lt;- matrix(0, 15, 3) table[1,1:2] &lt;- MSE.lm.basic table[2,1:2] &lt;- MSE.lm.flex table[3,1:2] &lt;- MSE.lasso table[4,1:2] &lt;- MSE.lasso.post table[5,1:2] &lt;- MSE.lasso.flex table[6,1:2] &lt;- MSE.lasso.post.flex table[7,1:2] &lt;- MSE.lasso.cv table[8,1:2] &lt;- MSE.ridge table[9,1:2] &lt;- MSE.elnet table[10,1:2] &lt;- MSE.lasso.cv.flex table[11,1:2] &lt;- MSE.ridge.flex table[12,1:2] &lt;- MSE.elnet.flex table[13,1:2] &lt;- MSE.rf table[14,1:2] &lt;- MSE.boost table[15,1:2] &lt;- MSE.pt table[1,3] &lt;- R2.lm.basic table[2,3] &lt;- R2.lm.flex table[3,3] &lt;- R2.lasso table[4,3] &lt;- R2.lasso.post table[5,3] &lt;- R2.lasso.flex table[6,3] &lt;- R2.lasso.post.flex table[7,3] &lt;- R2.lasso.cv table[8,3] &lt;- R2.ridge table[9,3] &lt;- R2.elnet table[10,3] &lt;- R2.lasso.cv.flex table[11,3] &lt;- R2.ridge.flex table[12,3] &lt;- R2.elnet.flex table[13,3] &lt;- R2.rf table[14,3] &lt;- R2.boost table[15,3] &lt;- R2.pt colnames(table)&lt;- c(&quot;MSE&quot;, &quot;S.E. for MSE&quot;, &quot;R-squared&quot;) rownames(table)&lt;- c(&quot;Least Squares (basic)&quot;,&quot;Least Squares (flexible)&quot;, &quot;Lasso&quot;, &quot;Post-Lasso&quot;,&quot;Lasso (flexible)&quot;,&quot;Post-Lasso (flexible)&quot;, &quot;Cross-Validated lasso&quot;, &quot;Cross-Validated ridge&quot;,&quot;Cross-Validated elnet&quot;,&quot;Cross-Validated lasso (flexible)&quot;,&quot;Cross-Validated ridge (flexible)&quot;,&quot;Cross-Validated elnet (flexible)&quot;, &quot;Random Forest&quot;,&quot;Boosted Trees&quot;, &quot;Pruned Tree&quot;) tab &lt;- xtable(table, digits =3) print(tab,type=&quot;latex&quot;) # set type=&quot;latex&quot; for printing table in LaTeX ## % latex table generated in R 4.1.1 by xtable 1.8-4 package ## % Thu Nov 04 12:18:07 2021 ## \\begin{table}[ht] ## \\centering ## \\begin{tabular}{rrrr} ## \\hline ## &amp; MSE &amp; S.E. for MSE &amp; R-squared \\\\ ## \\hline ## Least Squares (basic) &amp; 0.229 &amp; 0.016 &amp; 0.282 \\\\ ## Least Squares (flexible) &amp; 0.243 &amp; 0.016 &amp; 0.238 \\\\ ## Lasso &amp; 0.234 &amp; 0.015 &amp; 0.267 \\\\ ## Post-Lasso &amp; 0.233 &amp; 0.015 &amp; 0.271 \\\\ ## Lasso (flexible) &amp; 0.235 &amp; 0.015 &amp; 0.265 \\\\ ## Post-Lasso (flexible) &amp; 0.236 &amp; 0.016 &amp; 0.261 \\\\ ## Cross-Validated lasso &amp; 0.229 &amp; 0.015 &amp; 0.282 \\\\ ## Cross-Validated ridge &amp; 0.234 &amp; 0.015 &amp; 0.267 \\\\ ## Cross-Validated elnet &amp; 0.230 &amp; 0.015 &amp; 0.280 \\\\ ## Cross-Validated lasso (flexible) &amp; 0.232 &amp; 0.015 &amp; 0.275 \\\\ ## Cross-Validated ridge (flexible) &amp; 0.233 &amp; 0.015 &amp; 0.271 \\\\ ## Cross-Validated elnet (flexible) &amp; 0.231 &amp; 0.015 &amp; 0.276 \\\\ ## Random Forest &amp; 0.233 &amp; 0.015 &amp; 0.270 \\\\ ## Boosted Trees &amp; 0.230 &amp; 0.015 &amp; 0.279 \\\\ ## Pruned Tree &amp; 0.248 &amp; 0.016 &amp; 0.224 \\\\ ## \\hline ## \\end{tabular} ## \\end{table} Weight OLS Weight Lasso Constant -0.162 -0.147 Least Squares (basic) 0.281 0.293 Post-Lasso (flexible) 0.237 0.223 Cross-Validated elnet (flexible) -0.068 -0.056 Pruned Tree -0.140 0.000 Random Forest 0.377 0.344 Boosted Trees 0.367 0.245   # in process Above, we displayed the results for a single split of data into the training and testing part. The table shows the test MSE in column 1 as well as the standard error in column 2 and the test \\(R^2\\) in column 3. We see that the prediction rule produced by Elastic Net using the flexible model performs the best here, giving the lowest test MSE. Cross-Validated Lasso and Ridge, perform nearly as well. For any two of these methods, their testing MSEs are within one standard error of each other. Remarkably, OLS on a simple model performs extremely well, almost as well as best tree based method Random Forest. On the other hand, OLS on a flexible model with many regressors performs very poorly giving the highest test MSE. It is worth to notice that the nonlinear models, e.g. Random Forest, are not tuned. Thus, there is a lot of potential to improve the performance of the nonlinear methods we used in the analysis. 8.8 Ensemble learning In the final step, we can build a prediction model by combing the strengths of the models we considered so far. This ensemble method is of the form \\[ f(x) = \\sum_{k=1}^K \\alpha_k f_k(x) \\] where the \\(f_k\\)s denote our prediction rules from the table above and the \\(\\alpha_k\\)s are the corresponding weights. We focus on the prediction rules based on OLS, Post-Lasso, Elastic Net, Pruned Tree, Random Forest, Boosted Trees, and Neural Network and combine these methods into an ensemble method. The weights can be determined by a simple ols regression: ensemble.ols &lt;- summary(lm(Y_test~ yhat.lm.basic + yhat.rlasso.post.flex + yhat.elnet.flex+ yhat.pt+ yhat.rf + yhat.boost))   # in process Alternatively, we can determine the weights via lasso regression. ensemble.lasso &lt;- summary(rlasso(Y_test~ yhat.lm.basic + yhat.rlasso.post.flex + yhat.elnet.flex+ yhat.pt+ yhat.rf + yhat.boost)) ## ## Call: ## rlasso.formula(formula = Y_test ~ yhat.lm.basic + yhat.rlasso.post.flex + ## yhat.elnet.flex + yhat.pt + yhat.rf + yhat.boost) ## ## Post-Lasso Estimation: TRUE ## ## Total number of variables: 6 ## Number of selected variables: 5 ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.853465 -0.282571 -0.005527 0.263961 3.548724 ## ## Estimate ## (Intercept) -0.147 ## yhat.lm.basic 0.293 ## yhat.rlasso.post.flex 0.223 ## yhat.elnet.flex -0.056 ## yhat.pt 0.000 ## yhat.rf 0.344 ## yhat.boost 0.245 ## ## Residual standard error: 0.4728 ## Multiple R-squared: 0.3003 ## Adjusted R-squared: 0.2976 ## Joint significance test: ## the sup score statistic for joint significance test is 3.53 with a p-value of 0.04   # in process The estimated weights are shown in the following table. table &lt;- matrix(0, 7, 2) table[1:7,1] &lt;- ensemble.ols$coef[1:7] table[1:7,2] &lt;- ensemble.lasso$coef[1:7] colnames(table) &lt;- c(&quot;Weight OLS&quot;, &quot;Weight Lasso&quot;) rownames(table) &lt;- c(&quot;Constant&quot;,&quot;Least Squares (basic)&quot;,&quot;Post-Lasso (flexible)&quot;, &quot;Cross-Validated elnet (flexible)&quot;, &quot;Pruned Tree&quot;, &quot;Random Forest&quot;,&quot;Boosted Trees&quot;) tab &lt;- xtable(table, digits =3) print(tab,type=&quot;latex&quot;) # set type=&quot;latex&quot; for printing table in LaTeX ## % latex table generated in R 4.1.1 by xtable 1.8-4 package ## % Thu Nov 04 12:18:13 2021 ## \\begin{table}[ht] ## \\centering ## \\begin{tabular}{rrr} ## \\hline ## &amp; Weight OLS &amp; Weight Lasso \\\\ ## \\hline ## Constant &amp; -0.162 &amp; -0.147 \\\\ ## Least Squares (basic) &amp; 0.281 &amp; 0.293 \\\\ ## Post-Lasso (flexible) &amp; 0.237 &amp; 0.223 \\\\ ## Cross-Validated elnet (flexible) &amp; -0.068 &amp; -0.056 \\\\ ## Pruned Tree &amp; -0.140 &amp; 0.000 \\\\ ## Random Forest &amp; 0.377 &amp; 0.344 \\\\ ## Boosted Trees &amp; 0.367 &amp; 0.245 \\\\ ## \\hline ## \\end{tabular} ## \\end{table} Weight OLS Weight Lasso Constant -0.162 -0.147 Least Squares (basic) 0.281 0.293 Post-Lasso (flexible) 0.237 0.223 Cross-Validated elnet (flexible) -0.068 -0.056 Pruned Tree -0.140 0.000 Random Forest 0.377 0.344 Boosted Trees 0.367 0.245   # in process Further, the \\(R^2\\) for the test sample gets improved from \\(30\\%\\) obtained by OLS to about \\(31\\%\\) obtained by the ensemble method. We see that it is very powerful to aggregate prediction rules into an ensemble rule. Nevertheless, it is worth to notice that we should compare the ensemble method and the single rules on an additional validation set to ensure a fair comparison. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
