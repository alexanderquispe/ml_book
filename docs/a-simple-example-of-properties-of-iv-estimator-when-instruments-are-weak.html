<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 21 A Simple Example of Properties of IV estimator when Instruments are Weak | Machine Learning and Causal Inference</title>
  <meta name="description" content="Chapter 21 A Simple Example of Properties of IV estimator when Instruments are Weak | Machine Learning and Causal Inference" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 21 A Simple Example of Properties of IV estimator when Instruments are Weak | Machine Learning and Causal Inference" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 21 A Simple Example of Properties of IV estimator when Instruments are Weak | Machine Learning and Causal Inference" />
  
  
  

<meta name="author" content="Alexander Quispe &amp; Anzony Quispe" />


<meta name="date" content="2021-11-24" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="doubledebiased-ml-for-partially-linear-iv-model.html"/>
<link rel="next" href="hte-i-binary-treatment.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Machine Learning and Causal Inference</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="predictive-inference.html"><a href="predictive-inference.html"><i class="fa fa-check"></i><b>2</b> Predictive Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="predictive-inference.html"><a href="predictive-inference.html#data"><i class="fa fa-check"></i><b>2.1</b> Data</a></li>
<li class="chapter" data-level="2.2" data-path="predictive-inference.html"><a href="predictive-inference.html#data-analysis"><i class="fa fa-check"></i><b>2.2</b> Data Analysis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="predictive-inference.html"><a href="predictive-inference.html#r-and-python-code"><i class="fa fa-check"></i><b>2.2.1</b> R and Python code</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="predictive-inference.html"><a href="predictive-inference.html#prediction-question"><i class="fa fa-check"></i><b>2.3</b> Prediction Question</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="predictive-inference.html"><a href="predictive-inference.html#basic-model"><i class="fa fa-check"></i><b>2.3.1</b> Basic Model:</a></li>
<li class="chapter" data-level="2.3.2" data-path="predictive-inference.html"><a href="predictive-inference.html#flexible-model"><i class="fa fa-check"></i><b>2.3.2</b> Flexible Model:</a></li>
<li class="chapter" data-level="2.3.3" data-path="predictive-inference.html"><a href="predictive-inference.html#lasso-model"><i class="fa fa-check"></i><b>2.3.3</b> Lasso Model:</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="predictive-inference.html"><a href="predictive-inference.html#data-splitting"><i class="fa fa-check"></i><b>2.4</b> Data Splitting</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html"><i class="fa fa-check"></i><b>3</b> Predictive Inference The Gender Wage Gap</a>
<ul>
<li class="chapter" data-level="3.1" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#data-analysis-1"><i class="fa fa-check"></i><b>3.1</b> Data analysis</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#ols-regression"><i class="fa fa-check"></i><b>3.1.1</b> OLS Regression</a></li>
<li class="chapter" data-level="3.1.2" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#ols-regression-with-controls"><i class="fa fa-check"></i><b>3.1.2</b> Ols regression with controls</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#partialling-out-using-ols"><i class="fa fa-check"></i><b>3.2</b> Partialling-Out using ols</a></li>
<li class="chapter" data-level="3.3" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#partialling-out-using-lasso"><i class="fa fa-check"></i><b>3.3</b> Partialling-Out using lasso</a></li>
<li class="chapter" data-level="3.4" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#extra-flexible-model"><i class="fa fa-check"></i><b>3.4</b> “Extra” flexible model</a></li>
<li class="chapter" data-level="3.5" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#laso-extra-flexible-model"><i class="fa fa-check"></i><b>3.5</b> Laso “Extra” Flexible model</a></li>
<li class="chapter" data-level="3.6" data-path="predictive-inference-the-gender-wage-gap.html"><a href="predictive-inference-the-gender-wage-gap.html#summarize-the-results"><i class="fa fa-check"></i><b>3.6</b> Summarize the results</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html"><i class="fa fa-check"></i><b>4</b> Simple Exercise on Overfitting</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html#first-set-pn"><i class="fa fa-check"></i><b>4.1</b> 1. First set p=n</a></li>
<li class="chapter" data-level="4.2" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html#second-set-pn2."><i class="fa fa-check"></i><b>4.2</b> 2. Second, set p=n/2.</a></li>
<li class="chapter" data-level="4.3" data-path="simple-exercise-on-overfitting.html"><a href="simple-exercise-on-overfitting.html#third-set-pn-.05"><i class="fa fa-check"></i><b>4.3</b> 3. Third, set p/n =.05</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="vaccine-rct-examples.html"><a href="vaccine-rct-examples.html"><i class="fa fa-check"></i><b>5</b> Vaccine RCT Examples</a>
<ul>
<li class="chapter" data-level="5.1" data-path="vaccine-rct-examples.html"><a href="vaccine-rct-examples.html#polio-rct"><i class="fa fa-check"></i><b>5.1</b> Polio RCT</a></li>
<li class="chapter" data-level="5.2" data-path="vaccine-rct-examples.html"><a href="vaccine-rct-examples.html#pfizerbntx-covid-19-rct"><i class="fa fa-check"></i><b>5.2</b> Pfizer/BNTX Covid-19 RCT</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="penalized-linear-regressions-a-simulation-experiment.html"><a href="penalized-linear-regressions-a-simulation-experiment.html"><i class="fa fa-check"></i><b>6</b> Penalized Linear Regressions: A Simulation Experiment</a>
<ul>
<li class="chapter" data-level="6.1" data-path="penalized-linear-regressions-a-simulation-experiment.html"><a href="penalized-linear-regressions-a-simulation-experiment.html#data-generating-process-approximately-sparse"><i class="fa fa-check"></i><b>6.1</b> Data Generating Process: Approximately Sparse</a></li>
<li class="chapter" data-level="6.2" data-path="penalized-linear-regressions-a-simulation-experiment.html"><a href="penalized-linear-regressions-a-simulation-experiment.html#data-generating-process-approximately-sparse-small-dense-part"><i class="fa fa-check"></i><b>6.2</b> Data Generating Process: Approximately Sparse + Small Dense Part</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="simulation-design.html"><a href="simulation-design.html"><i class="fa fa-check"></i><b>7</b> Simulation Design</a>
<ul>
<li class="chapter" data-level="7.1" data-path="simulation-design.html"><a href="simulation-design.html#example-1"><i class="fa fa-check"></i><b>7.1</b> Example 1</a></li>
<li class="chapter" data-level="7.2" data-path="simulation-design.html"><a href="simulation-design.html#example-2"><i class="fa fa-check"></i><b>7.2</b> Example 2</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html"><i class="fa fa-check"></i><b>8</b> Testing the Convergence Hypothesis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#data-analysis-2"><i class="fa fa-check"></i><b>8.2</b> Data analysis</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#ols"><i class="fa fa-check"></i><b>8.2.1</b> OLS</a></li>
<li class="chapter" data-level="8.2.2" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#lasso"><i class="fa fa-check"></i><b>8.2.2</b> Lasso</a></li>
<li class="chapter" data-level="8.2.3" data-path="testing-the-convergence-hypothesis.html"><a href="testing-the-convergence-hypothesis.html#summary-results"><i class="fa fa-check"></i><b>8.2.3</b> Summary results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html"><i class="fa fa-check"></i><b>9</b> Machine Learning for wage prediction</a>
<ul>
<li class="chapter" data-level="9.1" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#data-1"><i class="fa fa-check"></i><b>9.1</b> Data</a></li>
<li class="chapter" data-level="9.2" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#analysis"><i class="fa fa-check"></i><b>9.2</b> Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#ols-1"><i class="fa fa-check"></i><b>9.3</b> OLS</a></li>
<li class="chapter" data-level="9.4" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#lasso-ridge-and-elastic-net"><i class="fa fa-check"></i><b>9.4</b> Lasso, Ridge and Elastic Net</a></li>
<li class="chapter" data-level="9.5" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#non-linear-models"><i class="fa fa-check"></i><b>9.5</b> Non-linear models</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#regression-trees"><i class="fa fa-check"></i><b>9.5.1</b> Regression Trees</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#random-forest-and-boosted-trees"><i class="fa fa-check"></i><b>9.6</b> Random Forest and Boosted Trees</a></li>
<li class="chapter" data-level="9.7" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#results"><i class="fa fa-check"></i><b>9.7</b> Results</a></li>
<li class="chapter" data-level="9.8" data-path="machine-learning-for-wage-prediction.html"><a href="machine-learning-for-wage-prediction.html#ensemble-learning"><i class="fa fa-check"></i><b>9.8</b> Ensemble learning</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="deep-neural-networks-for-wage-prediction.html"><a href="deep-neural-networks-for-wage-prediction.html"><i class="fa fa-check"></i><b>10</b> Deep Neural Networks for Wage Prediction</a>
<ul>
<li class="chapter" data-level="10.1" data-path="deep-neural-networks-for-wage-prediction.html"><a href="deep-neural-networks-for-wage-prediction.html#data-preparation"><i class="fa fa-check"></i><b>10.1</b> Data Preparation</a></li>
<li class="chapter" data-level="10.2" data-path="deep-neural-networks-for-wage-prediction.html"><a href="deep-neural-networks-for-wage-prediction.html#neural-networks"><i class="fa fa-check"></i><b>10.2</b> Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html"><i class="fa fa-check"></i><b>11</b> Functional Approximations by Trees and Neural Networks</a>
<ul>
<li class="chapter" data-level="11.1" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#functional-approximation-by-a-tree"><i class="fa fa-check"></i><b>11.1</b> Functional Approximation by a Tree</a></li>
<li class="chapter" data-level="11.2" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#functional-approximation-by-rf"><i class="fa fa-check"></i><b>11.2</b> Functional Approximation by RF</a></li>
<li class="chapter" data-level="11.3" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#boosted-trees"><i class="fa fa-check"></i><b>11.3</b> Boosted Trees</a></li>
<li class="chapter" data-level="11.4" data-path="functional-approximations-by-trees-and-neural-networks.html"><a href="functional-approximations-by-trees-and-neural-networks.html#same-example-with-a-neural-network"><i class="fa fa-check"></i><b>11.4</b> Same Example with a Neural Network</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><i class="fa fa-check"></i><b>12</b> Causal Identification in DAGs using Backdoor and Swigs, Equivalence Classes, Falsifiability Tests</a>
<ul>
<li class="chapter" data-level="12.1" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#graph-generation-and-plotting"><i class="fa fa-check"></i><b>12.1</b> Graph Generation and Plotting</a></li>
<li class="chapter" data-level="12.2" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#report-relatives-of-x2"><i class="fa fa-check"></i><b>12.2</b> Report Relatives of X2</a></li>
<li class="chapter" data-level="12.3" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#find-paths-between-d-and-y"><i class="fa fa-check"></i><b>12.3</b> Find Paths Between D and Y</a></li>
<li class="chapter" data-level="12.4" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#list-all-testable-implications-of-the-model"><i class="fa fa-check"></i><b>12.4</b> List All Testable Implications of the Model</a></li>
<li class="chapter" data-level="12.5" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#identification-by-backdoor-list-minimal-adjustment-sets-to-identify-causal-effecs-d-to-y"><i class="fa fa-check"></i><b>12.5</b> Identification by Backdoor: List minimal adjustment sets to identify causal effecs <span class="math inline">\(D \to Y\)</span></a></li>
<li class="chapter" data-level="12.6" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#identification-via-swig-and-d-separation"><i class="fa fa-check"></i><b>12.6</b> Identification via SWIG and D-separation</a></li>
<li class="chapter" data-level="12.7" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#deduce-conditional-exogeneity-or-ignorability-by-d-separation"><i class="fa fa-check"></i><b>12.7</b> Deduce Conditional Exogeneity or Ignorability by D-separation</a></li>
<li class="chapter" data-level="12.8" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#print-all-average-effects-identifiable-by-conditioning"><i class="fa fa-check"></i><b>12.8</b> Print All Average Effects Identifiable by Conditioning</a></li>
<li class="chapter" data-level="12.9" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#equivalence-classes"><i class="fa fa-check"></i><b>12.9</b> Equivalence Classes</a></li>
<li class="chapter" data-level="12.10" data-path="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html"><a href="causal-identification-in-dags-using-backdoor-and-swigs-equivalence-classes-falsifiability-tests.html#example-of-testing-dag-validity"><i class="fa fa-check"></i><b>12.10</b> Example of Testing DAG Validity</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="dosearch-for-causal-identification-in-dags.html"><a href="dosearch-for-causal-identification-in-dags.html"><i class="fa fa-check"></i><b>13</b> Dosearch for Causal Identification in DAGs</a></li>
<li class="chapter" data-level="14" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><i class="fa fa-check"></i><b>14</b> A Case Study: The Effect of Gun Ownership on Gun-Homicide Rates</a>
<ul>
<li class="chapter" data-level="14.1" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#data-2"><i class="fa fa-check"></i><b>14.1</b> Data</a></li>
<li class="chapter" data-level="14.2" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#preprocessing."><i class="fa fa-check"></i><b>14.2</b> Preprocessing.</a></li>
<li class="chapter" data-level="14.3" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#the-effect-of-gun-ownership"><i class="fa fa-check"></i><b>14.3</b> The effect of gun ownership</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#ols-2"><i class="fa fa-check"></i><b>14.3.1</b> OLS</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#dml-algorithm"><i class="fa fa-check"></i><b>14.4</b> DML algorithm</a></li>
<li class="chapter" data-level="14.5" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#lasso-1"><i class="fa fa-check"></i><b>14.5</b> Lasso</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html"><a href="a-case-study-the-effect-of-gun-ownership-on-gun-homicide-rates.html#random-forest"><i class="fa fa-check"></i><b>14.5.1</b> Random Forest</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><a href="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><i class="fa fa-check"></i><b>15</b> The Effect of Gun Ownership on Gun-Homicide Rates using DML for neural nets</a>
<ul>
<li class="chapter" data-level="15.1" data-path="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><a href="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html#dml-for-neural-nets"><i class="fa fa-check"></i><b>15.1</b> DML for neural nets</a></li>
<li class="chapter" data-level="15.2" data-path="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html"><a href="the-effect-of-gun-ownership-on-gun-homicide-rates-using-dml-for-neural-nets.html#estimating-the-effect-with-dlm-for-neural-nets"><i class="fa fa-check"></i><b>15.2</b> Estimating the effect with DLM for neural nets</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><i class="fa fa-check"></i><b>16</b> Inference on Predictive and Causal Effects in High-Dimensional Nonlinear Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#impact-of-401k-on-financial-wealth"><i class="fa fa-check"></i><b>16.1</b> Impact of 401(k) on Financial Wealth</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#data-3"><i class="fa fa-check"></i><b>16.1.1</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#double-ml-package"><i class="fa fa-check"></i><b>16.2</b> Double ML package</a></li>
<li class="chapter" data-level="16.3" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#estimating-the-ate-of-401k-eligibility-on-net-financial-assets"><i class="fa fa-check"></i><b>16.3</b> Estimating the ATE of 401(k) Eligibility on Net Financial Assets</a></li>
<li class="chapter" data-level="16.4" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#partially-linear-regression-models-plr"><i class="fa fa-check"></i><b>16.4</b> Partially Linear Regression Models (PLR)</a></li>
<li class="chapter" data-level="16.5" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#interactive-regression-model-irm"><i class="fa fa-check"></i><b>16.5</b> Interactive Regression Model (IRM)</a></li>
<li class="chapter" data-level="16.6" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#local-average-treatment-effects-of-401k-participation-on-net-financial-assets"><i class="fa fa-check"></i><b>16.6</b> Local Average Treatment Effects of 401(k) Participation on Net Financial Assets</a></li>
<li class="chapter" data-level="16.7" data-path="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html"><a href="inference-on-predictive-and-causal-effects-in-high-dimensional-nonlinear-models.html#interactive-iv-model-iivm"><i class="fa fa-check"></i><b>16.7</b> Interactive IV Model (IIVM)</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><i class="fa fa-check"></i><b>17</b> Using Dagitty in the Analysis of Impact of 401(k) on Net Financial Wealth</a>
<ul>
<li class="chapter" data-level="17.1" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#graphs-for-401k-analsyis"><i class="fa fa-check"></i><b>17.1</b> Graphs for 401(K) Analsyis</a></li>
<li class="chapter" data-level="17.2" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#state-one-graph-where-f-determines-x-and-plot-it"><i class="fa fa-check"></i><b>17.2</b> State one graph (where F determines X) and plot it</a></li>
<li class="chapter" data-level="17.3" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#list-minimal-adjustment-sets-to-identify-causal-effecs-d-to-y"><i class="fa fa-check"></i><b>17.3</b> List minimal adjustment sets to identify causal effecs <span class="math inline">\(D \to Y\)</span></a></li>
<li class="chapter" data-level="17.4" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#what-is-the-underlying-principle"><i class="fa fa-check"></i><b>17.4</b> What is the underlying principle?</a></li>
<li class="chapter" data-level="17.5" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#another-graph-wherere-x-determine-f"><i class="fa fa-check"></i><b>17.5</b> Another Graph (wherere <span class="math inline">\(X\)</span> determine <span class="math inline">\(F\)</span>):</a></li>
<li class="chapter" data-level="17.6" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#one-more-graph-encompassing-previous-ones-where-f-x-are-jointly-determined-by-latent-factors-a.-we-can-allow-in-fact-the-whole-triple-d-f-x-to-be-jointly-determined-by-latent-factors-a."><i class="fa fa-check"></i><b>17.6</b> One more graph (encompassing previous ones), where (F, X) are jointly determined by latent factors <span class="math inline">\(A\)</span>. We can allow in fact the whole triple (D, F, X) to be jointly determined by latent factors <span class="math inline">\(A\)</span>.</a></li>
<li class="chapter" data-level="17.7" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#threat-to-idenitification-what-if-f-also-directly-affects-y-note-that-there-are-no-valid-adjustment-sets-in-this-case"><i class="fa fa-check"></i><b>17.7</b> Threat to Idenitification: What if <span class="math inline">\(F\)</span> also directly affects <span class="math inline">\(Y\)</span>? (Note that there are no valid adjustment sets in this case)</a></li>
<li class="chapter" data-level="17.8" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#introduce-match-amount-m-very-important-mediator-why-mediator.-m-is-not-observed.-luckily-adjusting-for-x-still-works-if-there-is-no-f-to-m-arrow."><i class="fa fa-check"></i><b>17.8</b> Introduce Match Amount <span class="math inline">\(M\)</span> (very important mediator, why mediator?). <span class="math inline">\(M\)</span> is not observed. Luckily adjusting for <span class="math inline">\(X\)</span> still works if there is no <span class="math inline">\(F \to M\)</span> arrow.</a></li>
<li class="chapter" data-level="17.9" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#if-there-is-f-to-m-arrow-then-adjusting-for-x-is-not-sufficient."><i class="fa fa-check"></i><b>17.9</b> If there is <span class="math inline">\(F \to M\)</span> arrow, then adjusting for <span class="math inline">\(X\)</span> is not sufficient.</a></li>
<li class="chapter" data-level="17.10" data-path="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html"><a href="using-dagitty-in-the-analysis-of-impact-of-401k-on-net-financial-wealth.html#question"><i class="fa fa-check"></i><b>17.10</b> Question:</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html"><a href="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html"><i class="fa fa-check"></i><b>18</b> Double/Debiased Machine Learning for the Partially Linear Regression Model.</a>
<ul>
<li class="chapter" data-level="18.1" data-path="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html"><a href="doubledebiased-machine-learning-for-the-partially-linear-regression-model..html#dml-algorithm-1"><i class="fa fa-check"></i><b>18.1</b> DML algorithm</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><i class="fa fa-check"></i><b>19</b> Sensititivy Analysis for Unobserved Confounder with DML and Sensmakr</a>
<ul>
<li class="chapter" data-level="19.1" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#here-we-experiment-with-using-package-sensemakr-in-conjunction-with-debiased-ml"><i class="fa fa-check"></i><b>19.1</b> Here we experiment with using package “sensemakr” in conjunction with debiased ML</a></li>
<li class="chapter" data-level="19.2" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#we-will-work-on"><i class="fa fa-check"></i><b>19.2</b> We will work on:</a></li>
<li class="chapter" data-level="19.3" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#take-out-village-fixed-effects-and-run-basic-linear-analysis"><i class="fa fa-check"></i><b>19.3</b> Take out village fixed effects and run basic linear analysis</a></li>
<li class="chapter" data-level="19.4" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#we-first-use-lasso-for-partilling-out-controls"><i class="fa fa-check"></i><b>19.4</b> We first use Lasso for Partilling Out Controls</a></li>
<li class="chapter" data-level="19.5" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#manual-bias-analysis"><i class="fa fa-check"></i><b>19.5</b> Manual Bias Analysis</a></li>
<li class="chapter" data-level="19.6" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#bias-analysis-with-sensemakr"><i class="fa fa-check"></i><b>19.6</b> Bias Analysis with Sensemakr</a></li>
<li class="chapter" data-level="19.7" data-path="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html"><a href="sensititivy-analysis-for-unobserved-confounder-with-dml-and-sensmakr.html#next-we-use-random-forest-as-ml-tool-for-partialling-out"><i class="fa fa-check"></i><b>19.7</b> Next We use Random Forest as ML tool for Partialling Out</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html"><i class="fa fa-check"></i><b>20</b> Double/Debiased ML for Partially Linear IV Model</a>
<ul>
<li class="chapter" data-level="20.1" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#partially-linear-iv-model"><i class="fa fa-check"></i><b>20.1</b> Partially Linear IV Model</a></li>
<li class="chapter" data-level="20.2" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#example"><i class="fa fa-check"></i><b>20.2</b> Example</a></li>
<li class="chapter" data-level="20.3" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#plivm-in-residualized-form"><i class="fa fa-check"></i><b>20.3</b> PLIVM in Residualized Form</a></li>
<li class="chapter" data-level="20.4" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#dml-for-pliv-model"><i class="fa fa-check"></i><b>20.4</b> DML for PLIV Model</a></li>
<li class="chapter" data-level="20.5" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#emprical-example-acemoglu-jonsohn-robinson-aer."><i class="fa fa-check"></i><b>20.5</b> Emprical Example: Acemoglu, Jonsohn, Robinson (AER).</a></li>
<li class="chapter" data-level="20.6" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#examine-if-we-have-weak-instruments"><i class="fa fa-check"></i><b>20.6</b> Examine if we have weak instruments</a></li>
<li class="chapter" data-level="20.7" data-path="doubledebiased-ml-for-partially-linear-iv-model.html"><a href="doubledebiased-ml-for-partially-linear-iv-model.html#we-do-have-weak-instruments-because-t-stats-in-regression-tilde-d-sim-tilde-z-are-less-than-4-in-absolute-value"><i class="fa fa-check"></i><b>20.7</b> We do have weak instruments, because t-stats in regression <span class="math inline">\(\tilde D \sim \tilde Z\)</span> are less than 4 in absolute value</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><i class="fa fa-check"></i><b>21</b> A Simple Example of Properties of IV estimator when Instruments are Weak</a>
<ul>
<li class="chapter" data-level="21.1" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#run-1000-trials-to-evaluate-distribution-of-the-iv-estimator"><i class="fa fa-check"></i><b>21.1</b> Run 1000 trials to evaluate distribution of the IV estimator</a></li>
<li class="chapter" data-level="21.2" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#plot-the-actual-distribution-against-the-normal-approximation-based-on-strong-instrument-assumption"><i class="fa fa-check"></i><b>21.2</b> Plot the Actual Distribution against the Normal Approximation (based on Strong Instrument Assumption)</a></li>
<li class="chapter" data-level="21.3" data-path="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#some-help-functions"><i class="fa fa-check"></i><b>21.3</b> Some Help Functions</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html"><i class="fa fa-check"></i><b>22</b> HTE I: Binary treatment</a>
<ul>
<li class="chapter" data-level="22.1" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#pre-specified-hypotheses"><i class="fa fa-check"></i><b>22.1</b> Pre-specified hypotheses</a></li>
<li class="chapter" data-level="22.2" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#data-driven-hypotheses"><i class="fa fa-check"></i><b>22.2</b> Data-driven hypotheses</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#via-causal-trees"><i class="fa fa-check"></i><b>22.2.1</b> Via causal trees</a></li>
<li class="chapter" data-level="22.2.2" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#via-grf"><i class="fa fa-check"></i><b>22.2.2</b> Via grf</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="hte-i-binary-treatment.html"><a href="hte-i-binary-treatment.html#further-reading"><i class="fa fa-check"></i><b>22.3</b> Further reading</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning and Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak" class="section level1" number="21">
<h1><span class="header-section-number">Chapter 21</span> A Simple Example of Properties of IV estimator when Instruments are Weak</h1>
<p>Simulation Design</p>
<style>
  .col2 {
    columns: 2 200px;         /* number of columns and width in pixels*/
    -webkit-columns: 2 200px; /* chrome, safari */
    -moz-columns: 2 200px;    /* firefox */
  }
  .col3 {
    columns: 3 100px;
    -webkit-columns: 3 100px;
    -moz-columns: 3 100px;
  }
</style>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation Design</span></span>
<span id="cb1-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hdm)</span>
<span id="cb1-4"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb1-5"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-5" aria-hidden="true" tabindex="-1"></a>B<span class="ot">=</span> <span class="dv">10000</span> <span class="co"># trials</span></span>
<span id="cb1-6"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-6" aria-hidden="true" tabindex="-1"></a>IVEst <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, B)</span>
<span id="cb1-7"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-7" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">100</span></span>
<span id="cb1-8"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-8" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">=</span> .<span class="dv">25</span>   <span class="co"># .2 weak IV</span></span>
<span id="cb1-9"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">#beta = 1   #   1 strong IV</span></span>
<span id="cb1-10"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-12" aria-hidden="true" tabindex="-1"></a>U <span class="ot">=</span>  <span class="fu">rnorm</span>(n)  </span>
<span id="cb1-13"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-13" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">=</span> <span class="fu">rnorm</span>(n)  <span class="co">#generate instrument</span></span>
<span id="cb1-14"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-14" aria-hidden="true" tabindex="-1"></a>D <span class="ot">=</span> beta<span class="sc">*</span>Z <span class="sc">+</span> U  <span class="co">#generate endogenougs variable</span></span>
<span id="cb1-15"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-15" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span>  D<span class="sc">+</span> U  <span class="co"># the true causal effect is 1</span></span>
<span id="cb1-16"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(D<span class="sc">~</span>Z))  <span class="co"># first stage is very weak here</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = D ~ Z)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.32416 -0.60361  0.00536  0.58305  2.29316 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  0.10885    0.09035   1.205  0.23118   
## Z            0.24907    0.09472   2.629  0.00993 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9028 on 98 degrees of freedom
## Multiple R-squared:  0.0659, Adjusted R-squared:  0.05637 
## F-statistic: 6.914 on 1 and 98 DF,  p-value: 0.009931</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hdmpy</span>
<span id="cb3-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb3-4"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb3-5"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-6"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-7"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> colors</span>
<span id="cb3-8"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.sandbox.regression.gmm <span class="im">import</span> IV2SLS</span>
<span id="cb3-9"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np                                                              </span>
<span id="cb3-10"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns                                                           </span>
<span id="cb3-11"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats                                                         </span>
<span id="cb3-12"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-13"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb3-14"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-14" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">&quot;ignore&quot;</span>)</span>
<span id="cb3-15"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation Design</span></span>
<span id="cb3-17"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed</span></span>
<span id="cb3-19"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-19" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb3-20"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-20" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb3-21"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-21" aria-hidden="true" tabindex="-1"></a>IVEst <span class="op">=</span> np.zeros( B )</span>
<span id="cb3-22"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-22" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb3-23"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-23" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> <span class="fl">.25</span></span>
<span id="cb3-24"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-25" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-26"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-26" aria-hidden="true" tabindex="-1"></a>sd <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb3-27"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-28"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-28" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> np.random.normal( mean , sd, n ).reshape( n, <span class="dv">1</span> )</span>
<span id="cb3-29"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-29" aria-hidden="true" tabindex="-1"></a>Z <span class="op">=</span> np.random.normal( mean , sd, n ).reshape( n, <span class="dv">1</span> )</span>
<span id="cb3-30"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-30" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> beta<span class="op">*</span>Z <span class="op">+</span> U </span>
<span id="cb3-31"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-31" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> D <span class="op">+</span> U</span>
<span id="cb3-32"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-33" aria-hidden="true" tabindex="-1"></a>mod <span class="op">=</span> sm.OLS(D, sm.add_constant(Z))    <span class="co"># Describe model</span></span>
<span id="cb3-34"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-34" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> mod.fit()</span>
<span id="cb3-35"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(res.summary())</span></code></pre></div>
<pre><code>##                             OLS Regression Results                            
## ==============================================================================
## Dep. Variable:                      y   R-squared:                       0.121
## Model:                            OLS   Adj. R-squared:                  0.112
## Method:                 Least Squares   F-statistic:                     13.47
## Date:                Wed, 24 Nov 2021   Prob (F-statistic):           0.000395
## Time:                        16:39:05   Log-Likelihood:                -142.05
## No. Observations:                 100   AIC:                             288.1
## Df Residuals:                      98   BIC:                             293.3
## Df Model:                           1                                         
## Covariance Type:            nonrobust                                         
## ==============================================================================
##                  coef    std err          t      P&gt;|t|      [0.025      0.975]
## ------------------------------------------------------------------------------
## const          0.0509      0.101      0.501      0.617      -0.151       0.252
## x1             0.3588      0.098      3.670      0.000       0.165       0.553
## ==============================================================================
## Omnibus:                        0.445   Durbin-Watson:                   1.865
## Prob(Omnibus):                  0.801   Jarque-Bera (JB):                0.594
## Skew:                           0.041   Prob(JB):                        0.743
## Kurtosis:                       2.632   Cond. No.                         1.09
## ==============================================================================
## 
## Notes:
## [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">tsls</span>(<span class="at">x=</span><span class="cn">NULL</span>, <span class="at">d=</span>D, <span class="at">y=</span>Y, <span class="at">z=</span>Z))  <span class="co">#</span></span></code></pre></div>
<pre><code>## [1] &quot;Estimates and Significance Testing from from tsls&quot;
##             Estimate Std. Error t value p value   
## d1           0.99626    0.38173   2.610 0.00906 **
## (Intercept)  0.10926    0.09824   1.112 0.26608   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb7-1" aria-hidden="true" tabindex="-1"></a>IV <span class="op">=</span> IV2SLS(Y, D, sm.add_constant(Z))</span>
<span id="cb7-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb7-2" aria-hidden="true" tabindex="-1"></a>IV_res <span class="op">=</span> IV.fit()</span>
<span id="cb7-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(IV_res.summary())</span></code></pre></div>
<pre><code>##                           IV2SLS Regression Results                           
## ==============================================================================
## Dep. Variable:                      y   R-squared:                       0.892
## Model:                         IV2SLS   Adj. R-squared:                  0.891
## Method:                     Two Stage   F-statistic:                       nan
##                         Least Squares   Prob (F-statistic):                nan
## Date:                Wed, 24 Nov 2021                                         
## Time:                        16:39:05                                         
## No. Observations:                 100                                         
## Df Residuals:                      99                                         
## Df Model:                           1                                         
## ==============================================================================
##                  coef    std err          t      P&gt;|t|      [0.025      0.975]
## ------------------------------------------------------------------------------
## x1             1.3230      0.180      7.365      0.000       0.967       1.679
## ==============================================================================
## Omnibus:                        0.446   Durbin-Watson:                   1.864
## Prob(Omnibus):                  0.800   Jarque-Bera (JB):                0.595
## Skew:                           0.044   Prob(JB):                        0.743
## Kurtosis:                       2.633   Cond. No.                         1.00
## ==============================================================================</code></pre>
</div>
</div>
<p>Note that the instrument is weak here (contolled by <span class="math inline">\(\beta\)</span>) – the t-stat is less than 4.</p>
<div id="run-1000-trials-to-evaluate-distribution-of-the-iv-estimator" class="section level2" number="21.1">
<h2><span class="header-section-number">21.1</span> Run 1000 trials to evaluate distribution of the IV estimator</h2>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation Design</span></span>
<span id="cb9-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb9-4"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-4" aria-hidden="true" tabindex="-1"></a>B<span class="ot">=</span> <span class="dv">10000</span> <span class="co"># trials</span></span>
<span id="cb9-5"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-5" aria-hidden="true" tabindex="-1"></a>IVEst <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">0</span>, B)</span>
<span id="cb9-6"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>B){</span>
<span id="cb9-8"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-8" aria-hidden="true" tabindex="-1"></a>U <span class="ot">=</span>  <span class="fu">rnorm</span>(n)  </span>
<span id="cb9-9"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-9" aria-hidden="true" tabindex="-1"></a>Z <span class="ot">=</span> <span class="fu">rnorm</span>(n)  <span class="co">#generate instrument</span></span>
<span id="cb9-10"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-10" aria-hidden="true" tabindex="-1"></a>D <span class="ot">=</span> beta<span class="sc">*</span>Z <span class="sc">+</span> U  <span class="co">#generate endogenougs variable</span></span>
<span id="cb9-11"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-11" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">=</span>  D<span class="sc">+</span> U  <span class="co"># the true causal effect is 1</span></span>
<span id="cb9-12"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-12" aria-hidden="true" tabindex="-1"></a>IVEst[i] <span class="ot">=</span> <span class="fu">coef</span>(<span class="fu">tsls</span>(<span class="at">x=</span><span class="cn">NULL</span>, <span class="at">d=</span>D, <span class="at">y=</span>Y, <span class="at">z=</span>Z))[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb9-13"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb9-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation design </span></span>
<span id="cb10-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed</span></span>
<span id="cb10-5"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-5" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb10-6"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-6" aria-hidden="true" tabindex="-1"></a>B <span class="op">=</span> <span class="dv">1000</span> <span class="co"># Trials</span></span>
<span id="cb10-7"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-7" aria-hidden="true" tabindex="-1"></a>IVEst <span class="op">=</span> np.zeros( B )</span>
<span id="cb10-8"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>( <span class="dv">0</span>, B ):</span>
<span id="cb10-10"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-10" aria-hidden="true" tabindex="-1"></a>    U <span class="op">=</span> np.random.normal( mean , sd, n ).reshape( n, <span class="dv">1</span> )</span>
<span id="cb10-11"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-11" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> np.random.normal( mean , sd, n ).reshape( n, <span class="dv">1</span> )</span>
<span id="cb10-12"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-12" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> beta<span class="op">*</span>Z <span class="op">+</span> U </span>
<span id="cb10-13"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-13" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> D <span class="op">+</span> U</span>
<span id="cb10-14"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-15"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-15" aria-hidden="true" tabindex="-1"></a>    IV <span class="op">=</span> IV2SLS(Y, D, sm.add_constant(Z))</span>
<span id="cb10-16"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-16" aria-hidden="true" tabindex="-1"></a>    IV_res <span class="op">=</span> IV.fit()</span>
<span id="cb10-17"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb10-18"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-18" aria-hidden="true" tabindex="-1"></a>    IVEst[ i ] <span class="op">=</span> IV_res.summary2().tables[<span class="dv">1</span>][<span class="st">&quot;Coef.&quot;</span>][<span class="dv">0</span>]</span>
<span id="cb10-19"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb10-19" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
</div>
</div>
</div>
<div id="plot-the-actual-distribution-against-the-normal-approximation-based-on-strong-instrument-assumption" class="section level2" number="21.2">
<h2><span class="header-section-number">21.2</span> Plot the Actual Distribution against the Normal Approximation (based on Strong Instrument Assumption)</h2>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(IVEst<span class="dv">-1</span>, <span class="at">n=</span><span class="dv">1000</span>, <span class="at">from=</span><span class="sc">-</span><span class="dv">5</span>, <span class="at">to=</span><span class="dv">5</span>),<span class="at">col=</span><span class="dv">4</span>, <span class="at">xlim=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>),  </span>
<span id="cb11-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb11-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab=</span> <span class="st">&quot;IV Estimator -True Effect&quot;</span>, <span class="at">main=</span><span class="st">&quot;Actual Distribution vs Gaussian&quot;</span>)</span>
<span id="cb11-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb11-4" aria-hidden="true" tabindex="-1"></a>val<span class="ot">=</span><span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="at">by=</span>.<span class="dv">05</span>)</span>
<span id="cb11-5"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb11-5" aria-hidden="true" tabindex="-1"></a>var <span class="ot">=</span> (<span class="dv">1</span><span class="sc">/</span>beta<span class="sc">^</span><span class="dv">2</span>)<span class="sc">*</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">100</span>) <span class="co"># theoretical variance of IV</span></span>
<span id="cb11-6"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb11-6" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">=</span> <span class="fu">sqrt</span>(var)</span>
<span id="cb11-7"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(val, <span class="fu">dnorm</span>(val, <span class="at">sd=</span>sd), <span class="at">col=</span><span class="dv">2</span>, <span class="at">lty=</span><span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdownproj_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb12-1" aria-hidden="true" tabindex="-1"></a>rejection.frequency <span class="ot">=</span> <span class="fu">sum</span>(( <span class="fu">abs</span>(IVEst<span class="dv">-1</span>)<span class="sc">/</span>sd <span class="sc">&gt;</span> <span class="fl">1.96</span>))<span class="sc">/</span>B</span></code></pre></div>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-2" aria-hidden="true" tabindex="-1"></a>val <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">5</span>,<span class="fl">5.5</span>,<span class="fl">0.05</span>)</span>
<span id="cb13-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-3" aria-hidden="true" tabindex="-1"></a>var <span class="op">=</span> (<span class="dv">1</span><span class="op">/</span>beta<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">100</span>)   <span class="co"># theoretical variance of IV</span></span>
<span id="cb13-4"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-4" aria-hidden="true" tabindex="-1"></a>sd <span class="op">=</span> np.sqrt(var)</span>
<span id="cb13-5"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-6" aria-hidden="true" tabindex="-1"></a>normal_dist <span class="op">=</span> np.random.normal(<span class="dv">0</span>,sd,val.shape[<span class="dv">0</span>])</span>
<span id="cb13-7"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># plotting both distibutions on the same figure</span></span>
<span id="cb13-9"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-9" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.kdeplot(IVEst<span class="op">-</span><span class="dv">1</span>, shade<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">&quot;r&quot;</span>)</span>
<span id="cb13-10"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-10" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> sns.kdeplot(normal_dist, shade<span class="op">=</span><span class="va">True</span>, color<span class="op">=</span><span class="st">&quot;b&quot;</span>)</span>
<span id="cb13-11"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb13-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&quot;Actual Distribution vs Gaussian&quot;</span>)</span></code></pre></div>
<pre><code>## Text(0.5, 1.0, &#39;Actual Distribution vs Gaussian&#39;)</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;IV Estimator -True Effect&#39;</span>)</span></code></pre></div>
<pre><code>## Text(0.5, 0, &#39;IV Estimator -True Effect&#39;)</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb17-1" aria-hidden="true" tabindex="-1"></a>plt.xlim(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>)</span>
<span id="cb17-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb17-2" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
<pre><code>## (-5.0, 5.0)</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">c</span>(<span class="st">&quot;Rejection Frequency is &quot;</span>, </span>
<span id="cb19-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb19-2" aria-hidden="true" tabindex="-1"></a>      rejection.frequency, <span class="st">&quot; while we expect it to be .05&quot;</span>))</span></code></pre></div>
<pre><code>## Rejection Frequency is  0.1401  while we expect it to be .05</code></pre>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb21-1" aria-hidden="true" tabindex="-1"></a>rejection_frequency <span class="op">=</span> np.<span class="bu">sum</span>(( np.<span class="bu">abs</span>(IVEst<span class="op">-</span><span class="dv">1</span>)<span class="op">/</span>sd <span class="op">&gt;</span> <span class="fl">1.96</span>))<span class="op">/</span>B</span>
<span id="cb21-2"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>( <span class="ss">f&quot;Rejection Frequency is </span><span class="sc">{</span>rejection_frequency<span class="sc">}</span><span class="ss"> ,while we expect it to be .05&quot;</span>)</span>
<span id="cb21-3"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb21-3" aria-hidden="true" tabindex="-1"></a>  </span></code></pre></div>
<pre><code>## Rejection Frequency is 0.079 ,while we expect it to be .05</code></pre>
</div>
</div>
</div>
<div id="some-help-functions" class="section level2" number="21.3">
<h2><span class="header-section-number">21.3</span> Some Help Functions</h2>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="fu">help</span>(tsls)</span></code></pre></div>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(IV2SLS)</span></code></pre></div>
<pre><code>## Help on class IV2SLS in module statsmodels.sandbox.regression.gmm:
## 
## class IV2SLS(statsmodels.base.model.LikelihoodModel)
##  |  IV2SLS(endog, exog, instrument=None)
##  |  
##  |  Instrumental variables estimation using Two-Stage Least-Squares (2SLS)
##  |  
##  |  
##  |  Parameters
##  |  ----------
##  |  endog : ndarray
##  |     Endogenous variable, 1-dimensional or 2-dimensional array nobs by 1
##  |  exog : ndarray
##  |     Explanatory variables, 1-dimensional or 2-dimensional array nobs by k
##  |  instrument : ndarray
##  |     Instruments for explanatory variables. Must contain both exog
##  |     variables that are not being instrumented and instruments
##  |  
##  |  Notes
##  |  -----
##  |  All variables in exog are instrumented in the calculations. If variables
##  |  in exog are not supposed to be instrumented, then these variables
##  |  must also to be included in the instrument array.
##  |  
##  |  Degrees of freedom in the calculation of the standard errors uses
##  |  `df_resid = (nobs - k_vars)`.
##  |  (This corresponds to the `small` option in Stata&#39;s ivreg2.)
##  |  
##  |  Method resolution order:
##  |      IV2SLS
##  |      statsmodels.base.model.LikelihoodModel
##  |      statsmodels.base.model.Model
##  |      builtins.object
##  |  
##  |  Methods defined here:
##  |  
##  |  __init__(self, endog, exog, instrument=None)
##  |      Initialize self.  See help(type(self)) for accurate signature.
##  |  
##  |  fit(self)
##  |      estimate model using 2SLS IV regression
##  |      
##  |      Returns
##  |      -------
##  |      results : instance of RegressionResults
##  |         regression result
##  |      
##  |      Notes
##  |      -----
##  |      This returns a generic RegressioResults instance as defined for the
##  |      linear models.
##  |      
##  |      Parameter estimates and covariance are correct, but other results
##  |      have not been tested yet, to see whether they apply without changes.
##  |  
##  |  initialize(self)
##  |      Initialize (possibly re-initialize) a Model instance.
##  |      
##  |      For example, if the the design matrix of a linear model changes then
##  |      initialized can be used to recompute values using the modified design
##  |      matrix.
##  |  
##  |  predict(self, params, exog=None)
##  |      Return linear predicted values from a design matrix.
##  |      
##  |      Parameters
##  |      ----------
##  |      exog : array_like
##  |          Design / exogenous data
##  |      params : array_like, optional after fit has been called
##  |          Parameters of a linear model
##  |      
##  |      Returns
##  |      -------
##  |      An array of fitted values
##  |      
##  |      Notes
##  |      -----
##  |      If the model as not yet been fit, params is not optional.
##  |  
##  |  whiten(self, X)
##  |      Not implemented
##  |  
##  |  ----------------------------------------------------------------------
##  |  Methods inherited from statsmodels.base.model.LikelihoodModel:
##  |  
##  |  hessian(self, params)
##  |      The Hessian matrix of the model.
##  |      
##  |      Parameters
##  |      ----------
##  |      params : ndarray
##  |          The parameters to use when evaluating the Hessian.
##  |      
##  |      Returns
##  |      -------
##  |      ndarray
##  |          The hessian evaluated at the parameters.
##  |  
##  |  information(self, params)
##  |      Fisher information matrix of model.
##  |      
##  |      Returns -1 * Hessian of the log-likelihood evaluated at params.
##  |      
##  |      Parameters
##  |      ----------
##  |      params : ndarray
##  |          The model parameters.
##  |  
##  |  loglike(self, params)
##  |      Log-likelihood of model.
##  |      
##  |      Parameters
##  |      ----------
##  |      params : ndarray
##  |          The model parameters used to compute the log-likelihood.
##  |      
##  |      Notes
##  |      -----
##  |      Must be overridden by subclasses.
##  |  
##  |  score(self, params)
##  |      Score vector of model.
##  |      
##  |      The gradient of logL with respect to each parameter.
##  |      
##  |      Parameters
##  |      ----------
##  |      params : ndarray
##  |          The parameters to use when evaluating the Hessian.
##  |      
##  |      Returns
##  |      -------
##  |      ndarray
##  |          The score vector evaluated at the parameters.
##  |  
##  |  ----------------------------------------------------------------------
##  |  Class methods inherited from statsmodels.base.model.Model:
##  |  
##  |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type
##  |      Create a Model from a formula and dataframe.
##  |      
##  |      Parameters
##  |      ----------
##  |      formula : str or generic Formula object
##  |          The formula specifying the model.
##  |      data : array_like
##  |          The data for the model. See Notes.
##  |      subset : array_like
##  |          An array-like object of booleans, integers, or index values that
##  |          indicate the subset of df to use in the model. Assumes df is a
##  |          `pandas.DataFrame`.
##  |      drop_cols : array_like
##  |          Columns to drop from the design matrix.  Cannot be used to
##  |          drop terms involving categoricals.
##  |      *args
##  |          Additional positional argument that are passed to the model.
##  |      **kwargs
##  |          These are passed to the model with one exception. The
##  |          ``eval_env`` keyword is passed to patsy. It can be either a
##  |          :class:`patsy:patsy.EvalEnvironment` object or an integer
##  |          indicating the depth of the namespace to use. For example, the
##  |          default ``eval_env=0`` uses the calling namespace. If you wish
##  |          to use a &quot;clean&quot; environment set ``eval_env=-1``.
##  |      
##  |      Returns
##  |      -------
##  |      model
##  |          The model instance.
##  |      
##  |      Notes
##  |      -----
##  |      data must define __getitem__ with the keys in the formula terms
##  |      args and kwargs are passed on to the model instantiation. E.g.,
##  |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.
##  |  
##  |  ----------------------------------------------------------------------
##  |  Readonly properties inherited from statsmodels.base.model.Model:
##  |  
##  |  endog_names
##  |      Names of endogenous variables.
##  |  
##  |  exog_names
##  |      Names of exogenous variables.
##  |  
##  |  ----------------------------------------------------------------------
##  |  Data descriptors inherited from statsmodels.base.model.Model:
##  |  
##  |  __dict__
##  |      dictionary for instance variables (if defined)
##  |  
##  |  __weakref__
##  |      list of weak references to the object (if defined)</code></pre>
</div>
</div>
<div class="columns">
<div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">help</span>(density)</span></code></pre></div>
</div><div class="column" style="width:1%;">
<p> 
<!-- an empty Div (with a white space), serving as
a column separator --></p>
</div><div class="column" style="width:49.5%;">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="a-simple-example-of-properties-of-iv-estimator-when-instruments-are-weak.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">help</span>(sns.kdeplot)</span></code></pre></div>
<pre><code>## Help on function kdeplot in module seaborn.distributions:
## 
## kdeplot(x=None, *, y=None, shade=None, vertical=False, kernel=None, bw=None, gridsize=200, cut=3, clip=None, legend=True, cumulative=False, shade_lowest=None, cbar=False, cbar_ax=None, cbar_kws=None, ax=None, weights=None, hue=None, palette=None, hue_order=None, hue_norm=None, multiple=&#39;layer&#39;, common_norm=True, common_grid=False, levels=10, thresh=0.05, bw_method=&#39;scott&#39;, bw_adjust=1, log_scale=None, color=None, fill=None, data=None, data2=None, **kwargs)
##     Plot univariate or bivariate distributions using kernel density estimation.
##     
##     A kernel density estimate (KDE) plot is a method for visualizing the
##     distribution of observations in a dataset, analagous to a histogram. KDE
##     represents the data using a continuous probability density curve in one or
##     more dimensions.
##     
##     The approach is explained further in the :ref:`user guide &lt;tutorial_kde&gt;`.
##     
##     Relative to a histogram, KDE can produce a plot that is less cluttered and
##     more interpretable, especially when drawing multiple distributions. But it
##     has the potential to introduce distortions if the underlying distribution is
##     bounded or not smooth. Like a histogram, the quality of the representation
##     also depends on the selection of good smoothing parameters.
##     
##     Parameters
##     ----------
##     x, y : vectors or keys in ``data``
##         Variables that specify positions on the x and y axes.
##     shade : bool
##         Alias for ``fill``. Using ``fill`` is recommended.
##     vertical : bool
##         Orientation parameter.
##     
##         .. deprecated:: 0.11.0
##            specify orientation by assigning the ``x`` or ``y`` variables.
##     
##     kernel : str
##         Function that defines the kernel.
##     
##         .. deprecated:: 0.11.0
##            support for non-Gaussian kernels has been removed.
##     
##     bw : str, number, or callable
##         Smoothing parameter.
##     
##         .. deprecated:: 0.11.0
##            see ``bw_method`` and ``bw_adjust``.
##     
##     gridsize : int
##         Number of points on each dimension of the evaluation grid.
##     cut : number, optional
##         Factor, multiplied by the smoothing bandwidth, that determines how
##         far the evaluation grid extends past the extreme datapoints. When
##         set to 0, truncate the curve at the data limits.
##     clip : pair of numbers None, or a pair of such pairs
##         Do not evaluate the density outside of these limits.
##     legend : bool
##         If False, suppress the legend for semantic variables.
##     cumulative : bool, optional
##         If True, estimate a cumulative distribution function.
##     shade_lowest : bool
##         If False, the area below the lowest contour will be transparent
##     
##         .. deprecated:: 0.11.0
##            see ``thresh``.
##     
##     cbar : bool
##         If True, add a colorbar to annotate the color mapping in a bivariate plot.
##         Note: Does not currently support plots with a ``hue`` variable well.
##     cbar_ax : :class:`matplotlib.axes.Axes`
##         Pre-existing axes for the colorbar.
##     cbar_kws : dict
##         Additional parameters passed to :meth:`matplotlib.figure.Figure.colorbar`.
##     ax : :class:`matplotlib.axes.Axes`
##         Pre-existing axes for the plot. Otherwise, call :func:`matplotlib.pyplot.gca`
##         internally.
##     weights : vector or key in ``data``
##         If provided, weight the kernel density estimation using these values.
##     hue : vector or key in ``data``
##         Semantic variable that is mapped to determine the color of plot elements.
##     palette : string, list, dict, or :class:`matplotlib.colors.Colormap`
##         Method for choosing the colors to use when mapping the ``hue`` semantic.
##         String values are passed to :func:`color_palette`. List or dict values
##         imply categorical mapping, while a colormap object implies numeric mapping.
##     hue_order : vector of strings
##         Specify the order of processing and plotting for categorical levels of the
##         ``hue`` semantic.
##     hue_norm : tuple or :class:`matplotlib.colors.Normalize`
##         Either a pair of values that set the normalization range in data units
##         or an object that will map from data units into a [0, 1] interval. Usage
##         implies numeric mapping.
##     multiple : {{&quot;layer&quot;, &quot;stack&quot;, &quot;fill&quot;}}
##         Method for drawing multiple elements when semantic mapping creates subsets.
##         Only relevant with univariate data.
##     common_norm : bool
##         If True, scale each conditional density by the number of observations
##         such that the total area under all densities sums to 1. Otherwise,
##         normalize each density independently.
##     common_grid : bool
##         If True, use the same evaluation grid for each kernel density estimate.
##         Only relevant with univariate data.
##     levels : int or vector
##         Number of contour levels or values to draw contours at. A vector argument
##         must have increasing values in [0, 1]. Levels correspond to iso-proportions
##         of the density: e.g., 20% of the probability mass will lie below the
##         contour drawn for 0.2. Only relevant with bivariate data.
##     thresh : number in [0, 1]
##         Lowest iso-proportion level at which to draw a contour line. Ignored when
##         ``levels`` is a vector. Only relevant with bivariate data.
##     bw_method : string, scalar, or callable, optional
##         Method for determining the smoothing bandwidth to use; passed to
##         :class:`scipy.stats.gaussian_kde`.
##     bw_adjust : number, optional
##         Factor that multiplicatively scales the value chosen using
##         ``bw_method``. Increasing will make the curve smoother. See Notes.
##     log_scale : bool or number, or pair of bools or numbers
##         Set a log scale on the data axis (or axes, with bivariate data) with the
##         given base (default 10), and evaluate the KDE in log space.
##     color : :mod:`matplotlib color &lt;matplotlib.colors&gt;`
##         Single color specification for when hue mapping is not used. Otherwise, the
##         plot will try to hook into the matplotlib property cycle.
##     fill : bool or None
##         If True, fill in the area under univariate density curves or between
##         bivariate contours. If None, the default depends on ``multiple``.
##     data : :class:`pandas.DataFrame`, :class:`numpy.ndarray`, mapping, or sequence
##         Input data structure. Either a long-form collection of vectors that can be
##         assigned to named variables or a wide-form dataset that will be internally
##         reshaped.
##     kwargs
##         Other keyword arguments are passed to one of the following matplotlib
##         functions:
##     
##         - :meth:`matplotlib.axes.Axes.plot` (univariate, ``fill=False``),
##         - :meth:`matplotlib.axes.Axes.fill_between` (univariate, ``fill=True``),
##         - :meth:`matplotlib.axes.Axes.contour` (bivariate, ``fill=False``),
##         - :meth:`matplotlib.axes.contourf` (bivariate, ``fill=True``).
##     
##     Returns
##     -------
##     :class:`matplotlib.axes.Axes`
##         The matplotlib axes containing the plot.
##     
##     See Also
##     --------
##     displot : Figure-level interface to distribution plot functions.
##     histplot : Plot a histogram of binned counts with optional normalization or smoothing.
##     ecdfplot : Plot empirical cumulative distribution functions.
##     jointplot : Draw a bivariate plot with univariate marginal distributions.
##     violinplot : Draw an enhanced boxplot using kernel density estimation.
##     
##     Notes
##     -----
##     
##     The *bandwidth*, or standard deviation of the smoothing kernel, is an
##     important parameter. Misspecification of the bandwidth can produce a
##     distorted representation of the data. Much like the choice of bin width in a
##     histogram, an over-smoothed curve can erase true features of a
##     distribution, while an under-smoothed curve can create false features out of
##     random variability. The rule-of-thumb that sets the default bandwidth works
##     best when the true distribution is smooth, unimodal, and roughly bell-shaped.
##     It is always a good idea to check the default behavior by using ``bw_adjust``
##     to increase or decrease the amount of smoothing.
##     
##     Because the smoothing algorithm uses a Gaussian kernel, the estimated density
##     curve can extend to values that do not make sense for a particular dataset.
##     For example, the curve may be drawn over negative values when smoothing data
##     that are naturally positive. The ``cut`` and ``clip`` parameters can be used
##     to control the extent of the curve, but datasets that have many observations
##     close to a natural boundary may be better served by a different visualization
##     method.
##     
##     Similar considerations apply when a dataset is naturally discrete or &quot;spiky&quot;
##     (containing many repeated observations of the same value). Kernel density
##     estimation will always produce a smooth curve, which would be misleading
##     in these situations.
##     
##     The units on the density axis are a common source of confusion. While kernel
##     density estimation produces a probability distribution, the height of the curve
##     at each point gives a density, not a probability. A probability can be obtained
##     only by integrating the density across a range. The curve is normalized so
##     that the integral over all possible values is 1, meaning that the scale of
##     the density axis depends on the data values.
##     
##     Examples
##     --------
##     
##     .. include:: ../docstrings/kdeplot.rst</code></pre>
</div>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="doubledebiased-ml-for-partially-linear-iv-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hte-i-binary-treatment.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/alexanderquispe/ml_book/edit/master/32-Weak-IV-Experiments.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/alexanderquispe/ml_book/blob/master/32-Weak-IV-Experiments.Rmd",
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
